{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Save merged dataset\nmerged_output = 'data/raw/movies_merged.csv'\ndf_merged.to_csv(merged_output, index=False)\n\nprint(f\"Merged dataset saved to: {merged_output}\")\nprint(f\"File size: {os.path.getsize(merged_output) / 1024:.1f} KB\")\nprint(f\"Total rows: {len(df_merged)}\")\nprint(f\"Total columns: {len(df_merged.columns)}\")\n\nprint(\"\\nColumn list:\")\nfor i, col in enumerate(df_merged.columns, 1):\n    print(f\"  {i}. {col}\")\n\nprint(\"\\n✅ Data collection complete!\")\nprint(\"Next step: Proceed to 02_data_cleaning_eda.ipynb\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Save Merged Dataset\n\nSave the combined TMDB + Box Office Mojo dataset for use in subsequent notebooks.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*60)\nprint(\"BOX OFFICE MOJO SCRAPING RESULTS\")\nprint(\"=\"*60)\n\n# Scraping success rate\ntotal_scraped = len(df_bom)\nsuccessful = df_bom['scrape_success'].sum()\nprint(f\"\\nScraping Success Rate:\")\nprint(f\"  Total attempted: {total_scraped}\")\nprint(f\"  Successful: {successful} ({successful/total_scraped*100:.1f}%)\")\nprint(f\"  Failed: {total_scraped - successful}\")\n\n# Most common errors\nif (total_scraped - successful) > 0:\n    print(\"\\nMost common errors:\")\n    error_counts = df_bom[~df_bom['scrape_success']]['error_message'].value_counts().head(5)\n    for error, count in error_counts.items():\n        print(f\"  {error}: {count}\")\n\n# Revenue coverage comparison\nprint(f\"\\n{'='*60}\")\nprint(\"REVENUE COVERAGE\")\nprint(\"=\"*60)\nprint(f\"\\nBefore BOM scraping:\")\nprint(f\"  TMDB revenue > 0: {(df_tmdb['revenue'] > 0).sum()} ({(df_tmdb['revenue'] > 0).sum()/len(df_tmdb)*100:.1f}%)\")\n\nprint(f\"\\nAfter BOM scraping:\")\nprint(f\"  BOM revenue available: {df_merged['worldwide_total'].notna().sum()} ({df_merged['worldwide_total'].notna().sum()/len(df_merged)*100:.1f}%)\")\nprint(f\"  Final revenue > 0: {(df_merged['revenue_final'] > 0).sum()} ({(df_merged['revenue_final'] > 0).sum()/len(df_merged)*100:.1f}%)\")\n\n# Gap filling analysis\ntmdb_missing = (df_merged['revenue'] == 0) | (df_merged['revenue'].isna())\nbom_filled = df_merged['worldwide_total'].notna()\ngaps_filled = (tmdb_missing & bom_filled).sum()\n\nprint(f\"\\nGap Filling:\")\nprint(f\"  TMDB revenue gaps: {tmdb_missing.sum()}\")\nprint(f\"  Gaps filled by BOM: {gaps_filled}\")\nprint(f\"  Gap fill rate: {gaps_filled/tmdb_missing.sum()*100:.1f}%\")\n\n# Revenue comparison for movies with both sources\nprint(f\"\\n{'='*60}\")\nprint(\"REVENUE COMPARISON (Movies with Both Sources)\")\nprint(\"=\"*60)\n\nboth = (df_merged['revenue'] > 0) & (df_merged['worldwide_total'].notna())\nif both.sum() > 0:\n    df_compare = df_merged[both].copy()\n    df_compare['diff'] = abs(df_compare['revenue'] - df_compare['worldwide_total'])\n    df_compare['diff_pct'] = df_compare['diff'] / df_compare['revenue'] * 100\n\n    print(f\"\\nCount: {len(df_compare)}\")\n    print(f\"Mean absolute difference: ${df_compare['diff'].mean():,.0f}\")\n    print(f\"Median absolute difference: ${df_compare['diff'].median():,.0f}\")\n    print(f\"Mean % difference: {df_compare['diff_pct'].mean():.1f}%\")\n    print(f\"Median % difference: {df_compare['diff_pct'].median():.1f}%\")\n    print(f\"\\nMovies with >20% difference: {(df_compare['diff_pct'] > 20).sum()} ({(df_compare['diff_pct'] > 20).sum()/len(df_compare)*100:.1f}%)\")\n    \n    # Show a few examples of large discrepancies\n    if (df_compare['diff_pct'] > 20).sum() > 0:\n        print(\"\\nExample large discrepancies:\")\n        large_diff = df_compare.nlargest(3, 'diff_pct')[['title', 'revenue', 'worldwide_total', 'diff_pct']]\n        for idx, row in large_diff.iterrows():\n            print(f\"  {row['title']}: TMDB=${row['revenue']:,} vs BOM=${row['worldwide_total']:,} ({row['diff_pct']:.1f}% diff)\")\n\n# Dataset readiness check\nprint(f\"\\n{'='*60}\")\nprint(\"DATASET READINESS\")\nprint(\"=\"*60)\n\n# Before BOM\ncomplete_before = (df_tmdb['budget'] > 0) & (df_tmdb['revenue'] > 0)\nprint(f\"\\nBefore BOM scraping:\")\nprint(f\"  Movies with budget > 0: {(df_tmdb['budget'] > 0).sum()}\")\nprint(f\"  Movies with revenue > 0: {(df_tmdb['revenue'] > 0).sum()}\")\nprint(f\"  Movies with BOTH budget & revenue: {complete_before.sum()} ({complete_before.sum()/len(df_tmdb)*100:.1f}%)\")\n\n# After BOM\ncomplete_after = (df_merged['budget'] > 0) & (df_merged['revenue_final'] > 0)\nprint(f\"\\nAfter BOM scraping:\")\nprint(f\"  Movies with budget > 0: {(df_merged['budget'] > 0).sum()}\")\nprint(f\"  Movies with revenue_final > 0: {(df_merged['revenue_final'] > 0).sum()}\")\nprint(f\"  Movies with BOTH budget & revenue: {complete_after.sum()} ({complete_after.sum()/len(df_merged)*100:.1f}%)\")\n\nimprovement = complete_after.sum() - complete_before.sum()\nprint(f\"\\nImprovement:\")\nprint(f\"  Additional complete movies: +{improvement}\")\nprint(f\"  Improvement rate: +{improvement/complete_before.sum()*100:.1f}%\")\n\n# Target assessment\nTARGET = 5000\nprint(f\"\\nTarget Assessment:\")\nif complete_after.sum() >= TARGET:\n    print(f\"  ✅ EXCEEDS {TARGET:,} movie target! ({complete_after.sum():,} complete movies)\")\nelse:\n    shortfall = TARGET - complete_after.sum()\n    print(f\"  ⚠️  Short by {shortfall:,} movies (have {complete_after.sum():,}, need {TARGET:,})\")\n    print(f\"  Completion: {complete_after.sum()/TARGET*100:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Quality Analysis\n\nAnalyze scraping results, gap filling, and dataset completeness.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Merge TMDB and BOM data on IMDb ID\ndf_merged = df_tmdb.merge(\n    df_bom[['imdb_id', 'domestic_total', 'opening_weekend', 'worldwide_total', 'international_total', 'bom_budget', 'scrape_success']],\n    on='imdb_id',\n    how='left'\n)\n\n# Create final revenue column - prefer BOM worldwide, fallback to TMDB revenue\ndf_merged['revenue_final'] = df_merged['worldwide_total'].fillna(df_merged['revenue'])\n\n# Track revenue source for transparency\ndf_merged['revenue_source'] = 'none'\ndf_merged.loc[df_merged['revenue'] > 0, 'revenue_source'] = 'tmdb'\ndf_merged.loc[df_merged['worldwide_total'].notna(), 'revenue_source'] = 'bom'\ndf_merged.loc[(df_merged['revenue'] > 0) & (df_merged['worldwide_total'].notna()), 'revenue_source'] = 'both'\n\nprint(\"=\"*60)\nprint(\"MERGE COMPLETE\")\nprint(\"=\"*60)\nprint(f\"\\nMerged dataset shape: {df_merged.shape}\")\nprint(f\"  Rows: {len(df_merged)}\")\nprint(f\"  Columns: {len(df_merged.columns)}\")\n\nprint(\"\\nRevenue source breakdown:\")\nprint(df_merged['revenue_source'].value_counts())\n\nprint(\"\\nNew columns added:\")\nprint(\"  - domestic_total (from BOM)\")\nprint(\"  - opening_weekend (from BOM)\")\nprint(\"  - worldwide_total (from BOM)\")\nprint(\"  - international_total (from BOM)\")\nprint(\"  - bom_budget (from BOM)\")\nprint(\"  - revenue_final (combined best source)\")\nprint(\"  - revenue_source (tracking field)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Merge TMDB and Box Office Mojo Data\n\nCombine the two data sources, preferring BOM revenue (more complete) over TMDB revenue.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save Box Office Mojo data as raw CSV\noutput_file = 'data/raw/revenue_boxofficemojo_raw.csv'\ndf_bom.to_csv(output_file, index=False)\n\nprint(f\"Box Office Mojo data saved to: {output_file}\")\nprint(f\"File size: {os.path.getsize(output_file) / 1024:.1f} KB\")\nprint(f\"Total rows: {len(df_bom)}\")\nprint(f\"Total columns: {len(df_bom.columns)}\")\n\n# Display first few rows\nprint(\"\\nFirst 5 rows:\")\nprint(df_bom.head())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Save Raw Box Office Mojo Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get all IMDb IDs from TMDB data\nimdb_ids = df_tmdb['imdb_id'].dropna().tolist()\n\nprint(f\"Starting Box Office Mojo scraping...\")\nprint(f\"Total movies to scrape: {len(imdb_ids)}\")\nprint(f\"Estimated time: {len(imdb_ids) * 2 / 3600:.1f} hours\")\nprint(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n\n# Run batch scraper with checkpointing\nscrape_start = time.time()\ndf_bom = scrape_bom_batch(\n    imdb_ids,\n    checkpoint_file='data/raw/bom_checkpoint.csv',\n    save_every=100\n)\nscrape_end = time.time()\n\nprint(f\"\\nFinished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"Total time: {(scrape_end - scrape_start) / 60:.1f} minutes ({(scrape_end - scrape_start) / 3600:.2f} hours)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Run Full Box Office Mojo Scraping\n\n**Note:** This will take approximately 3-4 hours. The scraper uses checkpointing, so it can be safely interrupted and resumed. Consider running overnight or during a long break.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test scraper on 5 sample movies\nprint(\"Testing Box Office Mojo scraper on sample movies...\\n\")\n\ntest_ids = df_tmdb.head(5)['imdb_id'].dropna().tolist()\n\nfor test_id in test_ids:\n    result = scrape_bom_movie(test_id)\n    \n    # Get movie title for context\n    title = df_tmdb[df_tmdb['imdb_id'] == test_id]['title'].values[0]\n    \n    print(f\"{test_id} ({title}):\")\n    print(f\"  Success: {result['scrape_success']}\")\n    print(f\"  Worldwide: ${result['worldwide_total']:,}\" if result['worldwide_total'] else f\"  Worldwide: None\")\n    print(f\"  Domestic: ${result['domestic_total']:,}\" if result['domestic_total'] else f\"  Domestic: None\")\n    print(f\"  Opening: ${result['opening_weekend']:,}\" if result['opening_weekend'] else f\"  Opening: None\")\n    if result['error_message']:\n        print(f\"  Error: {result['error_message']}\")\n    print()\n    \n    time.sleep(1.5)  # Rate limit during test\n\nprint(\"Test complete! If results look good, proceed to full scraping.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Test Scraping on Sample Movies\n\nBefore running the full 3-4 hour scraping job, test on a few movies to verify the scraping logic works correctly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def scrape_bom_batch(imdb_ids, checkpoint_file='data/raw/bom_checkpoint.csv', save_every=100):\n    \"\"\"\n    Scrape multiple movies with automatic checkpointing for resumability.\n    \n    If interrupted, the function can resume from the last checkpoint by\n    simply running again - it will load completed IMDb IDs and skip them.\n    \n    Args:\n        imdb_ids: List of IMDb IDs to scrape\n        checkpoint_file: Path to save progress (CSV format)\n        save_every: Save checkpoint every N movies\n    \n    Returns:\n        DataFrame with all scraped results\n    \"\"\"\n    # Load existing checkpoint if available\n    if os.path.exists(checkpoint_file):\n        df_checkpoint = pd.read_csv(checkpoint_file)\n        completed = set(df_checkpoint['imdb_id'].dropna())\n        results = df_checkpoint.to_dict('records')\n        print(f\"Resuming from checkpoint: {len(completed)} already scraped\")\n    else:\n        completed = set()\n        results = []\n        print(\"Starting fresh scrape (no checkpoint found)\")\n\n    # Filter to unscraped movies\n    remaining = [id for id in imdb_ids if id not in completed]\n    print(f\"Scraping {len(remaining)} movies...\")\n    print(f\"Estimated time: {len(remaining) * 2 / 3600:.1f} hours\\n\")\n\n    # Initialize rate limiter\n    limiter = BOMRateLimiter(delay=1.5)\n\n    # Scrape each movie\n    for i, imdb_id in enumerate(remaining, 1):\n        limiter.wait()  # Respect rate limit before each request\n\n        result = scrape_bom_movie(imdb_id)\n        results.append(result)\n\n        # Progress report every 50 movies\n        if i % 50 == 0:\n            success = sum(1 for r in results[-i:] if r['scrape_success'])\n            print(f\"  Progress: {i}/{len(remaining)} | Recent success rate: {success}/{min(i, 50)} ({success/min(i, 50)*100:.1f}%)\")\n\n        # Save checkpoint every N movies\n        if i % save_every == 0:\n            pd.DataFrame(results).to_csv(checkpoint_file, index=False)\n            print(f\"  Checkpoint saved ({len(results)} total movies)\")\n\n    # Final save\n    df = pd.DataFrame(results)\n    df.to_csv(checkpoint_file, index=False)\n    \n    # Calculate final statistics\n    total_success = df['scrape_success'].sum()\n    print(f\"\\n{'='*60}\")\n    print(f\"Scraping complete!\")\n    print(f\"  Total movies: {len(df)}\")\n    print(f\"  Successful: {total_success} ({total_success/len(df)*100:.1f}%)\")\n    print(f\"  Failed: {len(df) - total_success}\")\n    print(f\"{'='*60}\")\n\n    return df\n\nprint(\"Batch processing function loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def scrape_bom_movie(imdb_id, max_retries=3):\n    \"\"\"\n    Scrape revenue data for a single movie from Box Office Mojo.\n    \n    Handles various error conditions:\n    - 404: Movie not found in BOM\n    - 429: Rate limited (exponential backoff)\n    - 5xx: Server errors (retry with delays)\n    - Timeout: Network timeout (retry once)\n    - Other exceptions: Catch and log\n    \n    Args:\n        imdb_id: IMDb ID (e.g., 'tt1375666')\n        max_retries: Maximum retry attempts for recoverable errors\n    \n    Returns:\n        Dictionary with revenue data or error information\n    \"\"\"\n    url = f\"https://www.boxofficemojo.com/title/{imdb_id}\"\n    headers = {'User-Agent': 'Mozilla/5.0 (compatible; MovieDataCollector/1.0)'}\n\n    for attempt in range(max_retries):\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n\n            if response.status_code == 404:\n                # Movie not in Box Office Mojo database\n                return error_result(imdb_id, 'not_found')\n\n            elif response.status_code == 429:\n                # Rate limited - wait with exponential backoff\n                wait = 30 * (2 ** attempt)  # 30s, 60s, 120s\n                print(f\"  Rate limited for {imdb_id}, waiting {wait}s...\")\n                time.sleep(wait)\n                continue\n\n            elif response.status_code >= 500:\n                # Server error - retry if attempts remain\n                if attempt < max_retries - 1:\n                    print(f\"  Server error {response.status_code} for {imdb_id}, retrying...\")\n                    time.sleep(5)\n                    continue\n                return error_result(imdb_id, f'server_error_{response.status_code}')\n\n            elif response.status_code == 200:\n                # Success - parse the HTML\n                soup = BeautifulSoup(response.content, 'html.parser')\n                return parse_bom_revenue(soup, imdb_id)\n\n            else:\n                # Unexpected status code\n                return error_result(imdb_id, f'http_{response.status_code}')\n\n        except requests.Timeout:\n            # Network timeout - retry if attempts remain\n            if attempt < max_retries - 1:\n                print(f\"  Timeout for {imdb_id}, retrying...\")\n                time.sleep(2)\n                continue\n            return error_result(imdb_id, 'timeout')\n\n        except Exception as e:\n            # Catch-all for unexpected errors\n            error_msg = str(e)[:50]  # Truncate long error messages\n            return error_result(imdb_id, f'exception_{error_msg}')\n\n    # Max retries exhausted\n    return error_result(imdb_id, 'max_retries')\n\nprint(\"Main scraping function loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def parse_bom_revenue(soup, imdb_id):\n    \"\"\"\n    Extract revenue data from Box Office Mojo HTML using regex patterns.\n    \n    BOM pages have varied layouts, so regex provides flexibility to find\n    labeled dollar amounts regardless of exact HTML structure.\n    \n    Args:\n        soup: BeautifulSoup object of page HTML\n        imdb_id: IMDb ID for result dictionary\n    \n    Returns:\n        Dictionary with revenue fields or None values if not found\n    \"\"\"\n    import re\n\n    result = {\n        'imdb_id': imdb_id,\n        'domestic_total': None,\n        'opening_weekend': None,\n        'international_total': None,\n        'worldwide_total': None,\n        'bom_budget': None,\n        'scrape_success': True,\n        'error_message': None\n    }\n\n    # Get all text content from page\n    text = soup.get_text()\n\n    # Regex pattern to match currency amounts\n    currency_pattern = r'\\$[\\d,]+'\n\n    # Search patterns: look for label followed by currency amount\n    # Case-insensitive for fields that vary in capitalization\n    patterns = {\n        'opening_weekend': r'Opening.*?' + currency_pattern,\n        'domestic_total': r'Domestic.*?' + currency_pattern,\n        'international_total': r'International.*?' + currency_pattern,\n        'worldwide_total': r'Worldwide.*?' + currency_pattern,\n        'bom_budget': r'Budget.*?' + currency_pattern\n    }\n\n    for field, pattern in patterns.items():\n        # Use IGNORECASE for opening and budget (capitalization varies)\n        flags = re.IGNORECASE if field in ['opening_weekend', 'bom_budget'] else 0\n        match = re.search(pattern, text, flags)\n        \n        if match:\n            # Extract just the currency part from the matched text\n            currency_match = re.search(currency_pattern, match.group())\n            if currency_match:\n                result[field] = clean_currency(currency_match.group())\n\n    return result\n\nprint(\"HTML parsing function loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Box Office Mojo Helper Functions\n\nclass BOMRateLimiter:\n    \"\"\"Rate limiter for Box Office Mojo scraping (1.5s between requests)\"\"\"\n    def __init__(self, delay=1.5):\n        self.delay = delay\n        self.last_time = None\n\n    def wait(self):\n        \"\"\"Wait if needed to respect rate limit\"\"\"\n        if self.last_time:\n            elapsed = time.time() - self.last_time\n            if elapsed < self.delay:\n                time.sleep(self.delay - elapsed)\n        self.last_time = time.time()\n\n\ndef clean_currency(text):\n    \"\"\"\n    Convert currency string to integer.\n    \n    Examples:\n        '$123,456,789' -> 123456789\n        '$1,000' -> 1000\n        '–' or None -> None\n    \"\"\"\n    if not text or text == '–' or text == '-':\n        return None\n    # Remove $ and commas, convert to int\n    return int(text.replace('$', '').replace(',', ''))\n\n\ndef error_result(imdb_id, msg):\n    \"\"\"\n    Create standardized error result dictionary.\n    \n    Args:\n        imdb_id: IMDb ID that failed\n        msg: Error message/code\n    \n    Returns:\n        Dictionary with all fields set to None and error message\n    \"\"\"\n    return {\n        'imdb_id': imdb_id,\n        'domestic_total': None,\n        'opening_weekend': None,\n        'international_total': None,\n        'worldwide_total': None,\n        'bom_budget': None,\n        'scrape_success': False,\n        'error_message': msg\n    }\n\nprint(\"Box Office Mojo helper functions loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Data Collection\n",
    "\n",
    "## Purpose\n",
    "This notebook handles the collection of raw movie data from multiple sources including:\n",
    "- **TMDB API**: Movie metadata (budget, cast, crew, genres, runtime, release dates)\n",
    "- **Box Office Mojo**: Box office revenue data (opening weekend, total domestic, worldwide)\n",
    "- **OMDb API**: Supplemental metadata and IMDb ratings\n",
    "- **YouTube Data API**: Trailer view counts and engagement metrics\n",
    "\n",
    "## Objectives\n",
    "1. Set up API connections and test endpoints\n",
    "2. Write data collection functions with error handling and rate limiting\n",
    "3. Collect data for 3,000+ movies from 2010-2024\n",
    "4. Merge data sources on IMDb ID\n",
    "5. Save raw datasets to CSV files in `data/raw/` directory\n",
    "6. Perform initial data inspection\n",
    "\n",
    "## Outputs\n",
    "- `data/raw/movies_tmdb_raw.csv`\n",
    "- `data/raw/revenue_boxofficemojo_raw.csv`\n",
    "- `data/raw/trailers_youtube_raw.csv`\n",
    "\n",
    "## Notes\n",
    "- This notebook may take several hours to run due to API rate limits\n",
    "- Once data is collected, subsequent runs should load from saved CSV files\n",
    "- API keys should be stored in a `.env` file (not committed to git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys loaded:\n",
      "  TMDB: ✓\n",
      "  OMDb: ✓\n",
      "  YouTube: ✓\n",
      "\n",
      "Testing TMDB API connection...\n",
      "✓ TMDB API connection successful!\n",
      "  Test movie: Fight Club\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys\n",
    "TMDB_API_KEY = os.getenv('TMDB_API_KEY')\n",
    "OMDB_API_KEY = os.getenv('OMDB_API_KEY')\n",
    "YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "\n",
    "# Verify API keys are loaded\n",
    "print(\"API Keys loaded:\")\n",
    "print(f\"  TMDB: {'✓' if TMDB_API_KEY else '✗'}\")\n",
    "print(f\"  OMDb: {'✓' if OMDB_API_KEY else '✗'}\")\n",
    "print(f\"  YouTube: {'✓' if YOUTUBE_API_KEY else '✗'}\")\n",
    "\n",
    "# Test TMDB API connection\n",
    "print(\"\\nTesting TMDB API connection...\")\n",
    "test_url = f\"https://api.themoviedb.org/3/movie/550?api_key={TMDB_API_KEY}\"\n",
    "try:\n",
    "    response = requests.get(test_url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✓ TMDB API connection successful!\")\n",
    "        print(f\"  Test movie: {response.json()['title']}\")\n",
    "    else:\n",
    "        print(f\"✗ TMDB API error: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Connection error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Collection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# TMDB API Base URL\n",
    "TMDB_BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Rate limiter class to handle TMDB's 40 requests per 10 seconds limit\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_calls=40, time_period=10):\n",
    "        self.max_calls = max_calls\n",
    "        self.time_period = time_period\n",
    "        self.calls = []\n",
    "    \n",
    "    def wait_if_needed(self):\n",
    "        now = time.time()\n",
    "        # Remove calls older than time_period\n",
    "        self.calls = [call_time for call_time in self.calls if now - call_time < self.time_period]\n",
    "        \n",
    "        if len(self.calls) >= self.max_calls:\n",
    "            sleep_time = self.time_period - (now - self.calls[0]) + 0.1\n",
    "            print(f\"  Rate limit reached, waiting {sleep_time:.1f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            self.calls = []\n",
    "        \n",
    "        self.calls.append(time.time())\n",
    "\n",
    "# Initialize rate limiter\n",
    "rate_limiter = RateLimiter(max_calls=35, time_period=10)  # Using 35 to be safe\n",
    "\n",
    "def get_popular_movies_by_year(year, pages=5):\n",
    "    \"\"\"\n",
    "    Get popular movies for a specific year using TMDB discover endpoint.\n",
    "    \n",
    "    Args:\n",
    "        year: Release year (e.g., 2020)\n",
    "        pages: Number of pages to fetch (20 movies per page)\n",
    "    \n",
    "    Returns:\n",
    "        List of movie IDs\n",
    "    \"\"\"\n",
    "    movie_ids = []\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        rate_limiter.wait_if_needed()\n",
    "        \n",
    "        url = f\"{TMDB_BASE_URL}/discover/movie\"\n",
    "        params = {\n",
    "            'api_key': TMDB_API_KEY,\n",
    "            'language': 'en-US',\n",
    "            'sort_by': 'popularity.desc',\n",
    "            'primary_release_year': year,\n",
    "            'page': page,\n",
    "            'vote_count.gte': 50  # Minimum votes to ensure it's not obscure\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                movie_ids.extend([movie['id'] for movie in data['results']])\n",
    "            else:\n",
    "                print(f\"  Error fetching page {page} for year {year}: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Exception for year {year}, page {page}: {e}\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return movie_ids\n",
    "\n",
    "def get_movie_details(movie_id):\n",
    "    \"\"\"\n",
    "    Get detailed information for a specific movie.\n",
    "    \n",
    "    Args:\n",
    "        movie_id: TMDB movie ID\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with movie details or None if error\n",
    "    \"\"\"\n",
    "    rate_limiter.wait_if_needed()\n",
    "    \n",
    "    url = f\"{TMDB_BASE_URL}/movie/{movie_id}\"\n",
    "    params = {\n",
    "        'api_key': TMDB_API_KEY,\n",
    "        'append_to_response': 'credits,release_dates,videos'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"  Error fetching movie {movie_id}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Exception for movie {movie_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_movie_data(movie_details):\n",
    "    \"\"\"\n",
    "    Extract relevant fields from TMDB movie details.\n",
    "    \n",
    "    Args:\n",
    "        movie_details: Raw JSON response from TMDB\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted fields\n",
    "    \"\"\"\n",
    "    if not movie_details:\n",
    "        return None\n",
    "    \n",
    "    # Extract release dates to find US release\n",
    "    us_release_date = None\n",
    "    us_certification = None\n",
    "    if 'release_dates' in movie_details and 'results' in movie_details['release_dates']:\n",
    "        for country_release in movie_details['release_dates']['results']:\n",
    "            if country_release['iso_3166_1'] == 'US':\n",
    "                for release in country_release['release_dates']:\n",
    "                    if release.get('type') in [2, 3]:  # Theatrical release\n",
    "                        us_release_date = release.get('release_date')\n",
    "                        us_certification = release.get('certification')\n",
    "                        break\n",
    "                break\n",
    "    \n",
    "    # Extract cast (top 5 actors)\n",
    "    cast = []\n",
    "    if 'credits' in movie_details and 'cast' in movie_details['credits']:\n",
    "        cast = [\n",
    "            {\n",
    "                'id': actor['id'],\n",
    "                'name': actor['name'],\n",
    "                'order': actor['order']\n",
    "            }\n",
    "            for actor in movie_details['credits']['cast'][:5]\n",
    "        ]\n",
    "    \n",
    "    # Extract director and crew\n",
    "    director = None\n",
    "    if 'credits' in movie_details and 'crew' in movie_details['credits']:\n",
    "        for crew_member in movie_details['credits']['crew']:\n",
    "            if crew_member['job'] == 'Director':\n",
    "                director = {\n",
    "                    'id': crew_member['id'],\n",
    "                    'name': crew_member['name']\n",
    "                }\n",
    "                break\n",
    "    \n",
    "    # Extract YouTube trailer key\n",
    "    trailer_key = None\n",
    "    if 'videos' in movie_details and 'results' in movie_details['videos']:\n",
    "        for video in movie_details['videos']['results']:\n",
    "            if video['type'] == 'Trailer' and video['site'] == 'YouTube':\n",
    "                trailer_key = video['key']\n",
    "                break\n",
    "    \n",
    "    # Extract genres\n",
    "    genres = [genre['name'] for genre in movie_details.get('genres', [])]\n",
    "    \n",
    "    # Extract production companies\n",
    "    production_companies = [company['name'] for company in movie_details.get('production_companies', [])]\n",
    "    \n",
    "    return {\n",
    "        'tmdb_id': movie_details.get('id'),\n",
    "        'imdb_id': movie_details.get('imdb_id'),\n",
    "        'title': movie_details.get('title'),\n",
    "        'original_title': movie_details.get('original_title'),\n",
    "        'release_date': movie_details.get('release_date'),\n",
    "        'us_release_date': us_release_date,\n",
    "        'us_certification': us_certification,\n",
    "        'budget': movie_details.get('budget'),\n",
    "        'revenue': movie_details.get('revenue'),  # Note: TMDB revenue often incomplete\n",
    "        'runtime': movie_details.get('runtime'),\n",
    "        'genres': '|'.join(genres) if genres else None,\n",
    "        'primary_genre': genres[0] if genres else None,\n",
    "        'num_genres': len(genres),\n",
    "        'popularity': movie_details.get('popularity'),\n",
    "        'vote_average': movie_details.get('vote_average'),\n",
    "        'vote_count': movie_details.get('vote_count'),\n",
    "        'director_id': director['id'] if director else None,\n",
    "        'director_name': director['name'] if director else None,\n",
    "        'cast_ids': '|'.join([str(actor['id']) for actor in cast]),\n",
    "        'cast_names': '|'.join([actor['name'] for actor in cast]),\n",
    "        'production_companies': '|'.join(production_companies) if production_companies else None,\n",
    "        'num_production_companies': len(production_companies),\n",
    "        'original_language': movie_details.get('original_language'),\n",
    "        'production_countries': '|'.join([country['iso_3166_1'] for country in movie_details.get('production_countries', [])]),\n",
    "        'youtube_trailer_key': trailer_key,\n",
    "        'tagline': movie_details.get('tagline'),\n",
    "        'overview': movie_details.get('overview')\n",
    "    }\n",
    "\n",
    "def collect_movies_for_year_range(start_year, end_year, pages_per_year=5):\n",
    "    \"\"\"\n",
    "    Collect movie data for a range of years.\n",
    "    \n",
    "    Args:\n",
    "        start_year: Starting year (inclusive)\n",
    "        end_year: Ending year (inclusive)\n",
    "        pages_per_year: Number of pages to fetch per year\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with collected movie data\n",
    "    \"\"\"\n",
    "    all_movies = []\n",
    "    total_movies = 0\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"\\n=== Collecting movies for {year} ===\")\n",
    "        \n",
    "        # Get movie IDs for this year\n",
    "        movie_ids = get_popular_movies_by_year(year, pages=pages_per_year)\n",
    "        print(f\"  Found {len(movie_ids)} movie IDs for {year}\")\n",
    "        \n",
    "        # Get details for each movie\n",
    "        year_movies = 0\n",
    "        for i, movie_id in enumerate(movie_ids, 1):\n",
    "            if i % 20 == 0:\n",
    "                print(f\"  Progress: {i}/{len(movie_ids)} movies processed for {year}\")\n",
    "            \n",
    "            movie_details = get_movie_details(movie_id)\n",
    "            if movie_details:\n",
    "                extracted_data = extract_movie_data(movie_details)\n",
    "                if extracted_data:\n",
    "                    all_movies.append(extracted_data)\n",
    "                    year_movies += 1\n",
    "        \n",
    "        print(f\"  Collected {year_movies} movies for {year}\")\n",
    "        total_movies += year_movies\n",
    "        print(f\"  Total movies collected so far: {total_movies}\")\n",
    "    \n",
    "    df = pd.DataFrame(all_movies)\n",
    "    return df\n",
    "\n",
    "print(\"Data collection functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for 2010-2024\n",
      "Fetching 17 pages per year (~340 movies/year)\n",
      "Estimated total movies: ~5100\n",
      "This will take approximately 2-3 hours due to API rate limiting.\n",
      "\n",
      "\n",
      "=== Collecting movies for 2010 ===\n",
      "  Found 340 movie IDs for 2010\n",
      "  Rate limit reached, waiting 4.7 seconds...\n",
      "  Progress: 20/340 movies processed for 2010\n",
      "  Progress: 40/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 4.6 seconds...\n",
      "  Progress: 60/340 movies processed for 2010\n",
      "  Progress: 80/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 5.1 seconds...\n",
      "  Progress: 100/340 movies processed for 2010\n",
      "  Progress: 120/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 5.0 seconds...\n",
      "  Progress: 140/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 4.0 seconds...\n",
      "  Progress: 160/340 movies processed for 2010\n",
      "  Progress: 180/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 200/340 movies processed for 2010\n",
      "  Progress: 220/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 240/340 movies processed for 2010\n",
      "  Progress: 260/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 280/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 2.7 seconds...\n",
      "  Progress: 300/340 movies processed for 2010\n",
      "  Progress: 320/340 movies processed for 2010\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 340/340 movies processed for 2010\n",
      "  Collected 340 movies for 2010\n",
      "  Total movies collected so far: 340\n",
      "\n",
      "=== Collecting movies for 2011 ===\n",
      "  Found 340 movie IDs for 2011\n",
      "  Rate limit reached, waiting 4.3 seconds...\n",
      "  Progress: 20/340 movies processed for 2011\n",
      "  Progress: 40/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 5.2 seconds...\n",
      "  Progress: 60/340 movies processed for 2011\n",
      "  Progress: 80/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 5.8 seconds...\n",
      "  Progress: 100/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 5.2 seconds...\n",
      "  Progress: 120/340 movies processed for 2011\n",
      "  Progress: 140/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 5.0 seconds...\n",
      "  Progress: 160/340 movies processed for 2011\n",
      "  Progress: 180/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 2.8 seconds...\n",
      "  Progress: 200/340 movies processed for 2011\n",
      "  Progress: 220/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 240/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 260/340 movies processed for 2011\n",
      "  Progress: 280/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 300/340 movies processed for 2011\n",
      "  Progress: 320/340 movies processed for 2011\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 340/340 movies processed for 2011\n",
      "  Collected 340 movies for 2011\n",
      "  Total movies collected so far: 680\n",
      "\n",
      "=== Collecting movies for 2012 ===\n",
      "  Found 340 movie IDs for 2012\n",
      "  Rate limit reached, waiting 3.6 seconds...\n",
      "  Progress: 20/340 movies processed for 2012\n",
      "  Progress: 40/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 5.0 seconds...\n",
      "  Progress: 60/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 80/340 movies processed for 2012\n",
      "  Progress: 100/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 5.8 seconds...\n",
      "  Progress: 120/340 movies processed for 2012\n",
      "  Progress: 140/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 160/340 movies processed for 2012\n",
      "  Progress: 180/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 200/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 220/340 movies processed for 2012\n",
      "  Progress: 240/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 260/340 movies processed for 2012\n",
      "  Progress: 280/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 300/340 movies processed for 2012\n",
      "  Progress: 320/340 movies processed for 2012\n",
      "  Rate limit reached, waiting 2.9 seconds...\n",
      "  Progress: 340/340 movies processed for 2012\n",
      "  Collected 340 movies for 2012\n",
      "  Total movies collected so far: 1020\n",
      "\n",
      "=== Collecting movies for 2013 ===\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Found 340 movie IDs for 2013\n",
      "  Progress: 20/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 4.6 seconds...\n",
      "  Progress: 40/340 movies processed for 2013\n",
      "  Progress: 60/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 5.9 seconds...\n",
      "  Progress: 80/340 movies processed for 2013\n",
      "  Progress: 100/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 5.5 seconds...\n",
      "  Progress: 120/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 140/340 movies processed for 2013\n",
      "  Progress: 160/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 180/340 movies processed for 2013\n",
      "  Progress: 200/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 220/340 movies processed for 2013\n",
      "  Progress: 240/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 260/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 280/340 movies processed for 2013\n",
      "  Progress: 300/340 movies processed for 2013\n",
      "  Rate limit reached, waiting 3.6 seconds...\n",
      "  Progress: 320/340 movies processed for 2013\n",
      "  Progress: 340/340 movies processed for 2013\n",
      "  Collected 340 movies for 2013\n",
      "  Total movies collected so far: 1360\n",
      "\n",
      "=== Collecting movies for 2014 ===\n",
      "  Rate limit reached, waiting 3.9 seconds...\n",
      "  Found 340 movie IDs for 2014\n",
      "  Progress: 20/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 4.6 seconds...\n",
      "  Progress: 40/340 movies processed for 2014\n",
      "  Progress: 60/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 5.0 seconds...\n",
      "  Progress: 80/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 5.5 seconds...\n",
      "  Progress: 100/340 movies processed for 2014\n",
      "  Progress: 120/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 140/340 movies processed for 2014\n",
      "  Progress: 160/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 3.8 seconds...\n",
      "  Progress: 180/340 movies processed for 2014\n",
      "  Progress: 200/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 220/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 240/340 movies processed for 2014\n",
      "  Progress: 260/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 280/340 movies processed for 2014\n",
      "  Progress: 300/340 movies processed for 2014\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 320/340 movies processed for 2014\n",
      "  Progress: 340/340 movies processed for 2014\n",
      "  Collected 340 movies for 2014\n",
      "  Total movies collected so far: 1700\n",
      "\n",
      "=== Collecting movies for 2015 ===\n",
      "  Rate limit reached, waiting 2.8 seconds...\n",
      "  Found 340 movie IDs for 2015\n",
      "  Rate limit reached, waiting 4.7 seconds...\n",
      "  Progress: 20/340 movies processed for 2015\n",
      "  Progress: 40/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 5.7 seconds...\n",
      "  Progress: 60/340 movies processed for 2015\n",
      "  Progress: 80/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 5.2 seconds...\n",
      "  Progress: 100/340 movies processed for 2015\n",
      "  Progress: 120/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 5.9 seconds...\n",
      "  Progress: 140/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 4.2 seconds...\n",
      "  Progress: 160/340 movies processed for 2015\n",
      "  Progress: 180/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 200/340 movies processed for 2015\n",
      "  Progress: 220/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 240/340 movies processed for 2015\n",
      "  Progress: 260/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 280/340 movies processed for 2015\n",
      "  Progress: 300/340 movies processed for 2015\n",
      "  Rate limit reached, waiting 0.1 seconds...\n",
      "  Progress: 320/340 movies processed for 2015\n",
      "  Progress: 340/340 movies processed for 2015\n",
      "  Collected 340 movies for 2015\n",
      "  Total movies collected so far: 2040\n",
      "\n",
      "=== Collecting movies for 2016 ===\n",
      "  Rate limit reached, waiting 0.2 seconds...\n",
      "  Found 340 movie IDs for 2016\n",
      "  Progress: 20/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 40/340 movies processed for 2016\n",
      "  Progress: 60/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 3.7 seconds...\n",
      "  Progress: 80/340 movies processed for 2016\n",
      "  Progress: 100/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 4.8 seconds...\n",
      "  Progress: 120/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 5.1 seconds...\n",
      "  Progress: 140/340 movies processed for 2016\n",
      "  Progress: 160/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 2.4 seconds...\n",
      "  Progress: 180/340 movies processed for 2016\n",
      "  Progress: 200/340 movies processed for 2016\n",
      "  Progress: 220/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 0.1 seconds...\n",
      "  Progress: 240/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 1.0 seconds...\n",
      "  Progress: 260/340 movies processed for 2016\n",
      "  Progress: 280/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 0.9 seconds...\n",
      "  Progress: 300/340 movies processed for 2016\n",
      "  Progress: 320/340 movies processed for 2016\n",
      "  Rate limit reached, waiting 1.1 seconds...\n",
      "  Progress: 340/340 movies processed for 2016\n",
      "  Collected 340 movies for 2016\n",
      "  Total movies collected so far: 2380\n",
      "\n",
      "=== Collecting movies for 2017 ===\n",
      "  Found 340 movie IDs for 2017\n",
      "  Rate limit reached, waiting 1.9 seconds...\n",
      "  Progress: 20/340 movies processed for 2017\n",
      "  Progress: 40/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 0.3 seconds...\n",
      "  Progress: 60/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 1.4 seconds...\n",
      "  Progress: 80/340 movies processed for 2017\n",
      "  Progress: 100/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 4.1 seconds...\n",
      "  Progress: 120/340 movies processed for 2017\n",
      "  Progress: 140/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 160/340 movies processed for 2017\n",
      "  Progress: 180/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 0.7 seconds...\n",
      "  Progress: 200/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 1.4 seconds...\n",
      "  Progress: 220/340 movies processed for 2017\n",
      "  Progress: 240/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 1.2 seconds...\n",
      "  Progress: 260/340 movies processed for 2017\n",
      "  Progress: 280/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 300/340 movies processed for 2017\n",
      "  Progress: 320/340 movies processed for 2017\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 340/340 movies processed for 2017\n",
      "  Collected 340 movies for 2017\n",
      "  Total movies collected so far: 2720\n",
      "\n",
      "=== Collecting movies for 2018 ===\n",
      "  Rate limit reached, waiting 3.5 seconds...\n",
      "  Found 340 movie IDs for 2018\n",
      "  Progress: 20/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 40/340 movies processed for 2018\n",
      "  Progress: 60/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 5.7 seconds...\n",
      "  Progress: 80/340 movies processed for 2018\n",
      "  Progress: 100/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 120/340 movies processed for 2018\n",
      "  Progress: 140/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 5.5 seconds...\n",
      "  Progress: 160/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 3.5 seconds...\n",
      "  Progress: 180/340 movies processed for 2018\n",
      "  Progress: 200/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 220/340 movies processed for 2018\n",
      "  Progress: 240/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 260/340 movies processed for 2018\n",
      "  Progress: 280/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 300/340 movies processed for 2018\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 320/340 movies processed for 2018\n",
      "  Progress: 340/340 movies processed for 2018\n",
      "  Collected 340 movies for 2018\n",
      "  Total movies collected so far: 3060\n",
      "\n",
      "=== Collecting movies for 2019 ===\n",
      "  Rate limit reached, waiting 3.9 seconds...\n",
      "  Found 340 movie IDs for 2019\n",
      "  Progress: 20/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 4.6 seconds...\n",
      "  Progress: 40/340 movies processed for 2019\n",
      "  Progress: 60/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 80/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 100/340 movies processed for 2019\n",
      "  Progress: 120/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 5.5 seconds...\n",
      "  Progress: 140/340 movies processed for 2019\n",
      "  Progress: 160/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 3.7 seconds...\n",
      "  Progress: 180/340 movies processed for 2019\n",
      "  Progress: 200/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 220/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 240/340 movies processed for 2019\n",
      "  Progress: 260/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 280/340 movies processed for 2019\n",
      "  Progress: 300/340 movies processed for 2019\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 320/340 movies processed for 2019\n",
      "  Progress: 340/340 movies processed for 2019\n",
      "  Collected 340 movies for 2019\n",
      "  Total movies collected so far: 3400\n",
      "\n",
      "=== Collecting movies for 2020 ===\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Found 340 movie IDs for 2020\n",
      "  Progress: 20/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 4.9 seconds...\n",
      "  Progress: 40/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 5.7 seconds...\n",
      "  Progress: 60/340 movies processed for 2020\n",
      "  Progress: 80/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 100/340 movies processed for 2020\n",
      "  Progress: 120/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 140/340 movies processed for 2020\n",
      "  Progress: 160/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 0.7 seconds...\n",
      "  Progress: 180/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 200/340 movies processed for 2020\n",
      "  Progress: 220/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 240/340 movies processed for 2020\n",
      "  Progress: 260/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 280/340 movies processed for 2020\n",
      "  Progress: 300/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 320/340 movies processed for 2020\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 340/340 movies processed for 2020\n",
      "  Collected 340 movies for 2020\n",
      "  Total movies collected so far: 3740\n",
      "\n",
      "=== Collecting movies for 2021 ===\n",
      "  Found 340 movie IDs for 2021\n",
      "  Rate limit reached, waiting 3.8 seconds...\n",
      "  Progress: 20/340 movies processed for 2021\n",
      "  Progress: 40/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 60/340 movies processed for 2021\n",
      "  Progress: 80/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 5.7 seconds...\n",
      "  Progress: 100/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 5.4 seconds...\n",
      "  Progress: 120/340 movies processed for 2021\n",
      "  Progress: 140/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 4.9 seconds...\n",
      "  Progress: 160/340 movies processed for 2021\n",
      "  Progress: 180/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 200/340 movies processed for 2021\n",
      "  Progress: 220/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 3.1 seconds...\n",
      "  Progress: 240/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 260/340 movies processed for 2021\n",
      "  Progress: 280/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 300/340 movies processed for 2021\n",
      "  Progress: 320/340 movies processed for 2021\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 340/340 movies processed for 2021\n",
      "  Collected 340 movies for 2021\n",
      "  Total movies collected so far: 4080\n",
      "\n",
      "=== Collecting movies for 2022 ===\n",
      "  Found 340 movie IDs for 2022\n",
      "  Rate limit reached, waiting 4.1 seconds...\n",
      "  Progress: 20/340 movies processed for 2022\n",
      "  Progress: 40/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 5.2 seconds...\n",
      "  Progress: 60/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 4.3 seconds...\n",
      "  Progress: 80/340 movies processed for 2022\n",
      "  Progress: 100/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 120/340 movies processed for 2022\n",
      "  Progress: 140/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 4.9 seconds...\n",
      "  Progress: 160/340 movies processed for 2022\n",
      "  Progress: 180/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 200/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 2.6 seconds...\n",
      "  Progress: 220/340 movies processed for 2022\n",
      "  Progress: 240/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 2.9 seconds...\n",
      "  Progress: 260/340 movies processed for 2022\n",
      "  Progress: 280/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 300/340 movies processed for 2022\n",
      "  Progress: 320/340 movies processed for 2022\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 340/340 movies processed for 2022\n",
      "  Collected 340 movies for 2022\n",
      "  Total movies collected so far: 4420\n",
      "\n",
      "=== Collecting movies for 2023 ===\n",
      "  Rate limit reached, waiting 3.5 seconds...\n",
      "  Found 340 movie IDs for 2023\n",
      "  Progress: 20/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 5.3 seconds...\n",
      "  Progress: 40/340 movies processed for 2023\n",
      "  Progress: 60/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 5.7 seconds...\n",
      "  Progress: 80/340 movies processed for 2023\n",
      "  Progress: 100/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 120/340 movies processed for 2023\n",
      "  Progress: 140/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 3.4 seconds...\n",
      "  Progress: 160/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 180/340 movies processed for 2023\n",
      "  Progress: 200/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 2.1 seconds...\n",
      "  Progress: 220/340 movies processed for 2023\n",
      "  Progress: 240/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 2.8 seconds...\n",
      "  Progress: 260/340 movies processed for 2023\n",
      "  Progress: 280/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 300/340 movies processed for 2023\n",
      "  Rate limit reached, waiting 3.2 seconds...\n",
      "  Progress: 320/340 movies processed for 2023\n",
      "  Progress: 340/340 movies processed for 2023\n",
      "  Collected 340 movies for 2023\n",
      "  Total movies collected so far: 4760\n",
      "\n",
      "=== Collecting movies for 2024 ===\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Found 340 movie IDs for 2024\n",
      "  Progress: 20/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 4.4 seconds...\n",
      "  Progress: 40/340 movies processed for 2024\n",
      "  Progress: 60/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 5.1 seconds...\n",
      "  Progress: 80/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 5.4 seconds...\n",
      "  Progress: 100/340 movies processed for 2024\n",
      "  Progress: 120/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 5.6 seconds...\n",
      "  Progress: 140/340 movies processed for 2024\n",
      "  Progress: 160/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 3.5 seconds...\n",
      "  Progress: 180/340 movies processed for 2024\n",
      "  Progress: 200/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 3.3 seconds...\n",
      "  Progress: 220/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 2.0 seconds...\n",
      "  Progress: 240/340 movies processed for 2024\n",
      "  Progress: 260/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 280/340 movies processed for 2024\n",
      "  Progress: 300/340 movies processed for 2024\n",
      "  Rate limit reached, waiting 3.0 seconds...\n",
      "  Progress: 320/340 movies processed for 2024\n",
      "  Progress: 340/340 movies processed for 2024\n",
      "  Collected 340 movies for 2024\n",
      "  Total movies collected so far: 5100\n",
      "\n",
      "============================================================\n",
      "Data collection complete!\n",
      "Total movies collected: 5100\n",
      "Time elapsed: 25.8 minutes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Collect TMDB data for movies from 2010-2024\n",
    "# This will take a while due to rate limiting (approximately 2-3 hours)\n",
    "\n",
    "# Set parameters\n",
    "START_YEAR = 2010\n",
    "END_YEAR = 2024\n",
    "PAGES_PER_YEAR = 17  # 17 pages x 20 movies = ~340 movies per year x 15 years = ~5,100 movies\n",
    "\n",
    "print(f\"Starting data collection for {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"Fetching {PAGES_PER_YEAR} pages per year (~{PAGES_PER_YEAR * 20} movies/year)\")\n",
    "print(f\"Estimated total movies: ~{(END_YEAR - START_YEAR + 1) * PAGES_PER_YEAR * 20}\")\n",
    "print(f\"This will take approximately 2-3 hours due to API rate limiting.\\n\")\n",
    "\n",
    "# Collect the data\n",
    "start_time = time.time()\n",
    "df_tmdb = collect_movies_for_year_range(START_YEAR, END_YEAR, pages_per_year=PAGES_PER_YEAR)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Data collection complete!\")\n",
    "print(f\"Total movies collected: {len(df_tmdb)}\")\n",
    "print(f\"Time elapsed: {(end_time - start_time) / 60:.1f} minutes\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw/movies_tmdb_raw.csv\n",
      "File size: 3223.3 KB\n",
      "Total rows: 5100\n",
      "Total columns: 27\n"
     ]
    }
   ],
   "source": [
    "# Create data/raw directory if it doesn't exist\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'data/raw/movies_tmdb_raw.csv'\n",
    "df_tmdb.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_file}\")\n",
    "print(f\"File size: {os.path.getsize(output_file) / 1024:.1f} KB\")\n",
    "print(f\"Total rows: {len(df_tmdb)}\")\n",
    "print(f\"Total columns: {len(df_tmdb.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "\n",
      "Shape: (5100, 27)\n",
      "  Rows (movies): 5100\n",
      "  Columns (features): 27\n",
      "\n",
      "============================================================\n",
      "COLUMN NAMES\n",
      "============================================================\n",
      "['tmdb_id', 'imdb_id', 'title', 'original_title', 'release_date', 'us_release_date', 'us_certification', 'budget', 'revenue', 'runtime', 'genres', 'primary_genre', 'num_genres', 'popularity', 'vote_average', 'vote_count', 'director_id', 'director_name', 'cast_ids', 'cast_names', 'production_companies', 'num_production_companies', 'original_language', 'production_countries', 'youtube_trailer_key', 'tagline', 'overview']\n",
      "\n",
      "============================================================\n",
      "DATA TYPES\n",
      "============================================================\n",
      "tmdb_id                       int64\n",
      "imdb_id                      object\n",
      "title                        object\n",
      "original_title               object\n",
      "release_date                 object\n",
      "us_release_date              object\n",
      "us_certification             object\n",
      "budget                        int64\n",
      "revenue                       int64\n",
      "runtime                       int64\n",
      "genres                       object\n",
      "primary_genre                object\n",
      "num_genres                    int64\n",
      "popularity                  float64\n",
      "vote_average                float64\n",
      "vote_count                    int64\n",
      "director_id                 float64\n",
      "director_name                object\n",
      "cast_ids                     object\n",
      "cast_names                   object\n",
      "production_companies         object\n",
      "num_production_companies      int64\n",
      "original_language            object\n",
      "production_countries         object\n",
      "youtube_trailer_key          object\n",
      "tagline                      object\n",
      "overview                     object\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "MISSING VALUES\n",
      "============================================================\n",
      "                      Missing  Percentage\n",
      "us_release_date          2111        41.4\n",
      "us_certification         2111        41.4\n",
      "youtube_trailer_key       646        12.7\n",
      "production_companies       96         1.9\n",
      "imdb_id                     5         0.1\n",
      "director_id                 2         0.0\n",
      "director_name               2         0.0\n",
      "\n",
      "============================================================\n",
      "FIRST 5 ROWS\n",
      "============================================================\n",
      "   tmdb_id    imdb_id                                         title  \\\n",
      "0    27205  tt1375666                                     Inception   \n",
      "1    10138  tt1228705                                    Iron Man 2   \n",
      "2    38757  tt0398286                                       Tangled   \n",
      "3    12444  tt0926084  Harry Potter and the Deathly Hallows: Part 1   \n",
      "4    10191  tt0892769                      How to Train Your Dragon   \n",
      "\n",
      "                                 original_title release_date  \\\n",
      "0                                     Inception   2010-07-15   \n",
      "1                                    Iron Man 2   2010-04-28   \n",
      "2                                       Tangled   2010-11-24   \n",
      "3  Harry Potter and the Deathly Hallows: Part 1   2010-11-17   \n",
      "4                      How to Train Your Dragon   2010-03-18   \n",
      "\n",
      "            us_release_date us_certification     budget    revenue  runtime  \\\n",
      "0  2010-07-16T00:00:00.000Z            PG-13  160000000  839030630      148   \n",
      "1  2010-05-07T00:00:00.000Z            PG-13  200000000  623933331      124   \n",
      "2  2010-11-24T00:00:00.000Z               PG  260000000  592461732      100   \n",
      "3  2010-11-19T00:00:00.000Z            PG-13  250000000  954305868      146   \n",
      "4  2010-03-26T00:00:00.000Z               PG  165000000  495141736       98   \n",
      "\n",
      "   ...      director_name                      cast_ids  \\\n",
      "0  ...  Christopher Nolan    6193|24045|3899|2524|27578   \n",
      "1  ...        Jon Favreau     3223|12052|1896|1245|6807   \n",
      "2  ...       Byron Howard   16855|69899|2517|2372|22132   \n",
      "3  ...        David Yates  10980|10990|10989|13014|1283   \n",
      "4  ...      Chris Sanders   449|17276|24264|59174|21007   \n",
      "\n",
      "                                          cast_names  \\\n",
      "0  Leonardo DiCaprio|Joseph Gordon-Levitt|Ken Wat...   \n",
      "1  Robert Downey Jr.|Gwyneth Paltrow|Don Cheadle|...   \n",
      "2  Mandy Moore|Zachary Levi|Donna Murphy|Ron Perl...   \n",
      "3  Daniel Radcliffe|Emma Watson|Rupert Grint|Toby...   \n",
      "4  Jay Baruchel|Gerard Butler|Craig Ferguson|Amer...   \n",
      "\n",
      "                                production_companies  \\\n",
      "0   Legendary Pictures|Syncopy|Warner Bros. Pictures   \n",
      "1  Marvel Studios|Fairview Entertainment|Marvel E...   \n",
      "2  Walt Disney Animation Studios|Walt Disney Pict...   \n",
      "3                 Warner Bros. Pictures|Heyday Films   \n",
      "4                               DreamWorks Animation   \n",
      "\n",
      "   num_production_companies  original_language  production_countries  \\\n",
      "0                         3                 en                 GB|US   \n",
      "1                         3                 en                    US   \n",
      "2                         2                 en                    US   \n",
      "3                         2                 en                 GB|US   \n",
      "4                         1                 en                    US   \n",
      "\n",
      "  youtube_trailer_key                                            tagline  \\\n",
      "0         cdx31ak4KbQ               Your mind is the scene of the crime.   \n",
      "1         BoohRoVA9WQ  It's not the armor that makes the hero, but th...   \n",
      "2         gsYKF8ecC8g           They're taking adventure to new lengths.   \n",
      "3         Su1LOpjvdZ4                                   Nowhere is safe.   \n",
      "4         KZtbJ_I9IFM              One adventure will change two worlds.   \n",
      "\n",
      "                                            overview  \n",
      "0  Cobb, a skilled thief who commits corporate es...  \n",
      "1  With the world now aware of his dual life as t...  \n",
      "2  Feisty teenager Rapunzel, who has long and mag...  \n",
      "3  Harry, Ron and Hermione walk away from their l...  \n",
      "4  As the son of a Viking leader on the cusp of m...  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "============================================================\n",
      "BASIC STATISTICS (Numeric Columns)\n",
      "============================================================\n",
      "            tmdb_id        budget       revenue      runtime   num_genres  \\\n",
      "count  5.100000e+03  5.100000e+03  5.100000e+03  5100.000000  5100.000000   \n",
      "mean   4.448168e+05  2.019610e+07  6.496997e+07   105.170392     2.538039   \n",
      "std    3.114871e+05  4.628629e+07  1.853822e+08    22.771213     1.042688   \n",
      "min    1.890000e+02  0.000000e+00  0.000000e+00     0.000000     1.000000   \n",
      "25%    1.775705e+05  0.000000e+00  0.000000e+00    92.000000     2.000000   \n",
      "50%    4.079050e+05  0.000000e+00  5.292900e+04   103.000000     3.000000   \n",
      "75%    6.326812e+05  1.500000e+07  3.188231e+07   117.000000     3.000000   \n",
      "max    1.387198e+06  5.839000e+08  2.799439e+09   317.000000     7.000000   \n",
      "\n",
      "        popularity  vote_average    vote_count   director_id  \\\n",
      "count  5100.000000   5100.000000   5100.000000  5.098000e+03   \n",
      "mean      4.960984      6.489497   1724.625882  5.920729e+05   \n",
      "std       3.090179      0.860767   3558.425260  7.615794e+05   \n",
      "min       1.454500      1.856000     50.000000  7.000000e+00   \n",
      "25%       3.460850      5.960000     97.000000  5.525200e+04   \n",
      "50%       4.275500      6.527500    265.500000  1.275140e+05   \n",
      "75%       5.382150      7.100000   1536.750000  1.150894e+06   \n",
      "max      66.371600      9.048000  38659.000000  4.773088e+06   \n",
      "\n",
      "       num_production_companies  \n",
      "count               5100.000000  \n",
      "mean                   3.491569  \n",
      "std                    2.495599  \n",
      "min                    0.000000  \n",
      "25%                    2.000000  \n",
      "50%                    3.000000  \n",
      "75%                    5.000000  \n",
      "max                   24.000000  \n",
      "\n",
      "============================================================\n",
      "KEY METRICS\n",
      "============================================================\n",
      "Movies with budget data: 5100 (100.0%)\n",
      "Movies with non-zero budget: 2256 (44.2%)\n",
      "Movies with revenue data: 5100 (100.0%)\n",
      "Movies with non-zero revenue: 2683 (52.6%)\n",
      "Movies with IMDb ID: 5095 (99.9%)\n",
      "Movies with director: 5098 (100.0%)\n",
      "Movies with cast data: 5100 (100.0%)\n",
      "Movies with YouTube trailer: 4454 (87.3%)\n",
      "\n",
      "============================================================\n",
      "SAMPLE MOVIES\n",
      "============================================================\n",
      "                             title release_date    budget    revenue  \\\n",
      "3331           New Biz in the Hood   2019-02-27   9598644          0   \n",
      "4497              Burning Betrayal   2023-10-25         0          0   \n",
      "3703                        Moffie   2020-03-13         0          0   \n",
      "1815         I Believe in Unicorns   2015-05-29      4999          0   \n",
      "1770                       Veteran   2015-08-05   7528230   87970000   \n",
      "4221                Vicini di casa   2022-12-01         0          0   \n",
      "53                         Get Low   2010-07-30    700000   10522511   \n",
      "1717  Kingsman: The Secret Service   2015-01-24  81000000  414351546   \n",
      "4218                   Incantation   2022-03-18         0    5700000   \n",
      "152                       Haunters   2010-11-10         0          0   \n",
      "\n",
      "     primary_genre    director_name  \n",
      "3331        Comedy   Mohamed Hamidi  \n",
      "4497         Drama    Diego Freitas  \n",
      "3703         Drama  Oliver Hermanus  \n",
      "1815         Drama   Leah Meyerhoff  \n",
      "1770        Action   Ryoo Seung-wan  \n",
      "4221        Comedy   Paolo Costella  \n",
      "53           Drama  Aaron Schneider  \n",
      "1717         Crime   Matthew Vaughn  \n",
      "4218        Horror         Kevin Ko  \n",
      "152       Thriller      Kim Min-suk  \n"
     ]
    }
   ],
   "source": [
    "# Basic data inspection\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nShape: {df_tmdb.shape}\")\n",
    "print(f\"  Rows (movies): {df_tmdb.shape[0]}\")\n",
    "print(f\"  Columns (features): {df_tmdb.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "print(df_tmdb.columns.tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\"*60)\n",
    "print(df_tmdb.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "missing = df_tmdb.isnull().sum()\n",
    "missing_pct = (missing / len(df_tmdb) * 100).round(1)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\"*60)\n",
    "print(df_tmdb.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASIC STATISTICS (Numeric Columns)\")\n",
    "print(\"=\"*60)\n",
    "print(df_tmdb.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Movies with budget data: {df_tmdb['budget'].notna().sum()} ({df_tmdb['budget'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with non-zero budget: {(df_tmdb['budget'] > 0).sum()} ({(df_tmdb['budget'] > 0).sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with revenue data: {df_tmdb['revenue'].notna().sum()} ({df_tmdb['revenue'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with non-zero revenue: {(df_tmdb['revenue'] > 0).sum()} ({(df_tmdb['revenue'] > 0).sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with IMDb ID: {df_tmdb['imdb_id'].notna().sum()} ({df_tmdb['imdb_id'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with director: {df_tmdb['director_name'].notna().sum()} ({df_tmdb['director_name'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with cast data: {df_tmdb['cast_names'].notna().sum()} ({df_tmdb['cast_names'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "print(f\"Movies with YouTube trailer: {df_tmdb['youtube_trailer_key'].notna().sum()} ({df_tmdb['youtube_trailer_key'].notna().sum() / len(df_tmdb) * 100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE MOVIES\")\n",
    "print(\"=\"*60)\n",
    "print(df_tmdb[['title', 'release_date', 'budget', 'revenue', 'primary_genre', 'director_name']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>us_release_date</th>\n",
       "      <th>us_certification</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>...</th>\n",
       "      <th>director_name</th>\n",
       "      <th>cast_ids</th>\n",
       "      <th>cast_names</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>num_production_companies</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>youtube_trailer_key</th>\n",
       "      <th>tagline</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>2010-07-16T00:00:00.000Z</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>160000000</td>\n",
       "      <td>839030630</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>6193|24045|3899|2524|27578</td>\n",
       "      <td>Leonardo DiCaprio|Joseph Gordon-Levitt|Ken Wat...</td>\n",
       "      <td>Legendary Pictures|Syncopy|Warner Bros. Pictures</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>GB|US</td>\n",
       "      <td>cdx31ak4KbQ</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10138</td>\n",
       "      <td>tt1228705</td>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>2010-04-28</td>\n",
       "      <td>2010-05-07T00:00:00.000Z</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>200000000</td>\n",
       "      <td>623933331</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>Jon Favreau</td>\n",
       "      <td>3223|12052|1896|1245|6807</td>\n",
       "      <td>Robert Downey Jr.|Gwyneth Paltrow|Don Cheadle|...</td>\n",
       "      <td>Marvel Studios|Fairview Entertainment|Marvel E...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>BoohRoVA9WQ</td>\n",
       "      <td>It's not the armor that makes the hero, but th...</td>\n",
       "      <td>With the world now aware of his dual life as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38757</td>\n",
       "      <td>tt0398286</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>2010-11-24T00:00:00.000Z</td>\n",
       "      <td>PG</td>\n",
       "      <td>260000000</td>\n",
       "      <td>592461732</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>Byron Howard</td>\n",
       "      <td>16855|69899|2517|2372|22132</td>\n",
       "      <td>Mandy Moore|Zachary Levi|Donna Murphy|Ron Perl...</td>\n",
       "      <td>Walt Disney Animation Studios|Walt Disney Pict...</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>gsYKF8ecC8g</td>\n",
       "      <td>They're taking adventure to new lengths.</td>\n",
       "      <td>Feisty teenager Rapunzel, who has long and mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12444</td>\n",
       "      <td>tt0926084</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>2010-11-19T00:00:00.000Z</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000</td>\n",
       "      <td>954305868</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>10980|10990|10989|13014|1283</td>\n",
       "      <td>Daniel Radcliffe|Emma Watson|Rupert Grint|Toby...</td>\n",
       "      <td>Warner Bros. Pictures|Heyday Films</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>GB|US</td>\n",
       "      <td>Su1LOpjvdZ4</td>\n",
       "      <td>Nowhere is safe.</td>\n",
       "      <td>Harry, Ron and Hermione walk away from their l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10191</td>\n",
       "      <td>tt0892769</td>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>2010-03-18</td>\n",
       "      <td>2010-03-26T00:00:00.000Z</td>\n",
       "      <td>PG</td>\n",
       "      <td>165000000</td>\n",
       "      <td>495141736</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>Chris Sanders</td>\n",
       "      <td>449|17276|24264|59174|21007</td>\n",
       "      <td>Jay Baruchel|Gerard Butler|Craig Ferguson|Amer...</td>\n",
       "      <td>DreamWorks Animation</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>KZtbJ_I9IFM</td>\n",
       "      <td>One adventure will change two worlds.</td>\n",
       "      <td>As the son of a Viking leader on the cusp of m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmdb_id    imdb_id                                         title  \\\n",
       "0    27205  tt1375666                                     Inception   \n",
       "1    10138  tt1228705                                    Iron Man 2   \n",
       "2    38757  tt0398286                                       Tangled   \n",
       "3    12444  tt0926084  Harry Potter and the Deathly Hallows: Part 1   \n",
       "4    10191  tt0892769                      How to Train Your Dragon   \n",
       "\n",
       "                                 original_title release_date  \\\n",
       "0                                     Inception   2010-07-15   \n",
       "1                                    Iron Man 2   2010-04-28   \n",
       "2                                       Tangled   2010-11-24   \n",
       "3  Harry Potter and the Deathly Hallows: Part 1   2010-11-17   \n",
       "4                      How to Train Your Dragon   2010-03-18   \n",
       "\n",
       "            us_release_date us_certification     budget    revenue  runtime  \\\n",
       "0  2010-07-16T00:00:00.000Z            PG-13  160000000  839030630      148   \n",
       "1  2010-05-07T00:00:00.000Z            PG-13  200000000  623933331      124   \n",
       "2  2010-11-24T00:00:00.000Z               PG  260000000  592461732      100   \n",
       "3  2010-11-19T00:00:00.000Z            PG-13  250000000  954305868      146   \n",
       "4  2010-03-26T00:00:00.000Z               PG  165000000  495141736       98   \n",
       "\n",
       "   ...      director_name                      cast_ids  \\\n",
       "0  ...  Christopher Nolan    6193|24045|3899|2524|27578   \n",
       "1  ...        Jon Favreau     3223|12052|1896|1245|6807   \n",
       "2  ...       Byron Howard   16855|69899|2517|2372|22132   \n",
       "3  ...        David Yates  10980|10990|10989|13014|1283   \n",
       "4  ...      Chris Sanders   449|17276|24264|59174|21007   \n",
       "\n",
       "                                          cast_names  \\\n",
       "0  Leonardo DiCaprio|Joseph Gordon-Levitt|Ken Wat...   \n",
       "1  Robert Downey Jr.|Gwyneth Paltrow|Don Cheadle|...   \n",
       "2  Mandy Moore|Zachary Levi|Donna Murphy|Ron Perl...   \n",
       "3  Daniel Radcliffe|Emma Watson|Rupert Grint|Toby...   \n",
       "4  Jay Baruchel|Gerard Butler|Craig Ferguson|Amer...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0   Legendary Pictures|Syncopy|Warner Bros. Pictures   \n",
       "1  Marvel Studios|Fairview Entertainment|Marvel E...   \n",
       "2  Walt Disney Animation Studios|Walt Disney Pict...   \n",
       "3                 Warner Bros. Pictures|Heyday Films   \n",
       "4                               DreamWorks Animation   \n",
       "\n",
       "   num_production_companies  original_language  production_countries  \\\n",
       "0                         3                 en                 GB|US   \n",
       "1                         3                 en                    US   \n",
       "2                         2                 en                    US   \n",
       "3                         2                 en                 GB|US   \n",
       "4                         1                 en                    US   \n",
       "\n",
       "  youtube_trailer_key                                            tagline  \\\n",
       "0         cdx31ak4KbQ               Your mind is the scene of the crime.   \n",
       "1         BoohRoVA9WQ  It's not the armor that makes the hero, but th...   \n",
       "2         gsYKF8ecC8g           They're taking adventure to new lengths.   \n",
       "3         Su1LOpjvdZ4                                   Nowhere is safe.   \n",
       "4         KZtbJ_I9IFM              One adventure will change two worlds.   \n",
       "\n",
       "                                            overview  \n",
       "0  Cobb, a skilled thief who commits corporate es...  \n",
       "1  With the world now aware of his dual life as t...  \n",
       "2  Feisty teenager Rapunzel, who has long and mag...  \n",
       "3  Harry, Ron and Hermione walk away from their l...  \n",
       "4  As the son of a Viking leader on the cusp of m...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Box Office Mojo Revenue Scraping\n\n### Purpose\nScrape box office revenue data from Box Office Mojo to fill gaps in TMDB data. Currently only 37% of movies have both budget and revenue, limiting our dataset size. Box Office Mojo provides comprehensive revenue data including opening weekend, domestic total, international, and worldwide gross.\n\n### Strategy\n- Target all 5,094 movies with IMDb IDs\n- Use respectful rate limiting (1.5s delays)\n- Implement checkpointing for resumability\n- Extract: opening weekend, domestic total, international total, worldwide total, budget",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}