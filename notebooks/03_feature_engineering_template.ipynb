{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Deep EDA & Feature Engineering\n",
    "\n",
    "**Author:** Nate DeMoro  \n",
    "**Date:** 2026-01-24  \n",
    "**Objective:** Transform cleaned dataset (2,095 movies) into feature-engineered dataset ready for modeling\n",
    "\n",
    "**Current State:**\n",
    "- Cleaned dataset: 2,095 movies (2010-2024)\n",
    "- Baseline RÂ² (budget only): 0.553\n",
    "- Target: RÂ² > 0.70 with engineered features\n",
    "\n",
    "**Implementation Plan:**\n",
    "- **Step 3.1:** Bivariate Analysis & Correlation Deep Dive\n",
    "- **Step 3.2:** Tier 1 Feature Engineering (temporal, cast/crew, competition)\n",
    "- **Step 3.3:** Tier 2 Features, Final EDA & Dataset Preparation\n",
    "\n",
    "**Critical:** No data leakage - all features must use only pre-release information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3.1: Bivariate Analysis & Correlation Deep Dive\n",
    "### 3.1.1 Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/processed/movies_cleaned.csv')\n",
    "\n",
    "# Convert date columns\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df['us_release_date'] = pd.to_datetime(df['us_release_date'])\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} movies Ã— {df.shape[1]} columns\")\n",
    "print(f\"Date range: {df['release_year'].min()} - {df['release_year'].max()}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid pre-release predictors (EXCLUDE post-release data)\n",
    "# From CLAUDE.md: vote_count, vote_average, popularity contain post-release data (leakage risk)\n",
    "\n",
    "INVALID_PREDICTORS = ['vote_count', 'vote_average', 'popularity', \n",
    "                      'opening_weekend', 'domestic_total', 'international_total']\n",
    "\n",
    "TARGET = 'revenue_worldwide'\n",
    "\n",
    "# Numeric features (pre-release)\n",
    "numeric_features = ['budget', 'runtime', 'num_genres', 'num_production_companies']\n",
    "\n",
    "# Categorical features (pre-release)\n",
    "categorical_features = ['primary_genre', 'us_certification', 'original_language', \n",
    "                       'is_english', 'release_month', 'release_year']\n",
    "\n",
    "print(\"âœ“ Valid predictors defined\")\n",
    "print(f\"  Numeric features: {len(numeric_features)}\")\n",
    "print(f\"  Categorical features: {len(categorical_features)}\")\n",
    "print(f\"  Target variable: {TARGET}\")\n",
    "print(f\"\\nâš  EXCLUDED (post-release data): {INVALID_PREDICTORS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Numeric Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget vs Revenue Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Linear scale\n",
    "axes[0, 0].scatter(df['budget'], df[TARGET], alpha=0.5, s=20)\n",
    "axes[0, 0].set_xlabel('Budget ($)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Revenue Worldwide ($)', fontsize=12)\n",
    "axes[0, 0].set_title('Budget vs Revenue (Linear Scale)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].ticklabel_format(style='plain', axis='both')\n",
    "\n",
    "# Add trendline\n",
    "z = np.polyfit(df['budget'], df[TARGET], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0, 0].plot(df['budget'], p(df['budget']), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "# Calculate correlation\n",
    "corr_budget = df['budget'].corr(df[TARGET])\n",
    "r2_budget = corr_budget ** 2\n",
    "axes[0, 0].text(0.05, 0.95, f'r = {corr_budget:.3f}\\nRÂ² = {r2_budget:.3f}', \n",
    "               transform=axes[0, 0].transAxes, fontsize=11, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Log-log scale\n",
    "df_nonzero = df[(df['budget'] > 0) & (df[TARGET] > 0)]\n",
    "axes[0, 1].scatter(np.log10(df_nonzero['budget']), np.log10(df_nonzero[TARGET]), alpha=0.5, s=20)\n",
    "axes[0, 1].set_xlabel('Log10(Budget)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Log10(Revenue)', fontsize=12)\n",
    "axes[0, 1].set_title('Budget vs Revenue (Log-Log Scale)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Budget quantiles\n",
    "budget_quantiles = pd.qcut(df['budget'], q=10, labels=[f'Q{i}' for i in range(1, 11)])\n",
    "budget_revenue_by_quantile = df.groupby(budget_quantiles)[TARGET].agg(['mean', 'median', 'count'])\n",
    "budget_revenue_by_quantile['mean'].plot(kind='bar', ax=axes[1, 0], color='steelblue')\n",
    "axes[1, 0].set_xlabel('Budget Quantile (Q1=Lowest, Q10=Highest)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[1, 0].set_title('Average Revenue by Budget Quantile', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "axes[1, 0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Residuals\n",
    "predicted = p(df['budget'])\n",
    "residuals = df[TARGET] - predicted\n",
    "axes[1, 1].scatter(predicted, residuals, alpha=0.5, s=20)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Predicted Revenue ($)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Residuals ($)', fontsize=12)\n",
    "axes[1, 1].set_title('Residual Plot (Budget Model)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].ticklabel_format(style='plain', axis='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/budget_vs_revenue_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Budget-Revenue Correlation: r = {corr_budget:.4f}, RÂ² = {r2_budget:.4f}\")\n",
    "print(f\"Budget explains {r2_budget*100:.1f}% of revenue variance (baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime Analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Runtime distribution\n",
    "axes[0].hist(df['runtime'], bins=40, edgecolor='black', color='skyblue')\n",
    "axes[0].set_xlabel('Runtime (minutes)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Runtime Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(df['runtime'].median(), color='red', linestyle='--', linewidth=2, label=f'Median: {df[\"runtime\"].median():.0f} min')\n",
    "axes[0].legend()\n",
    "\n",
    "# Runtime vs Revenue\n",
    "axes[1].scatter(df['runtime'], df[TARGET], alpha=0.5, s=20)\n",
    "axes[1].set_xlabel('Runtime (minutes)', fontsize=12)\n",
    "axes[1].set_ylabel('Revenue Worldwide ($)', fontsize=12)\n",
    "axes[1].set_title('Runtime vs Revenue', fontsize=14, fontweight='bold')\n",
    "corr_runtime = df['runtime'].corr(df[TARGET])\n",
    "axes[1].text(0.05, 0.95, f'r = {corr_runtime:.3f}', transform=axes[1].transAxes, \n",
    "            fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Runtime categories\n",
    "runtime_bins = [0, 90, 110, 130, 300]\n",
    "runtime_labels = ['Short (<90)', 'Standard (90-110)', 'Long (110-130)', 'Epic (>130)']\n",
    "df['runtime_category_temp'] = pd.cut(df['runtime'], bins=runtime_bins, labels=runtime_labels)\n",
    "runtime_revenue = df.groupby('runtime_category_temp', observed=True)[TARGET].agg(['mean', 'median', 'count'])\n",
    "runtime_revenue['mean'].plot(kind='bar', ax=axes[2], color='coral')\n",
    "axes[2].set_xlabel('Runtime Category', fontsize=12)\n",
    "axes[2].set_ylabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[2].set_title('Average Revenue by Runtime Category', fontsize=14, fontweight='bold')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/runtime_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Runtime Analysis:\")\n",
    "print(runtime_revenue)\n",
    "print(f\"\\nRuntime-Revenue Correlation: r = {corr_runtime:.4f}\")\n",
    "\n",
    "# Clean up temp column\n",
    "df.drop('runtime_category_temp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Summary for All Numeric Features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS: Numeric Features vs Revenue\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correlations = []\n",
    "for feature in numeric_features:\n",
    "    if feature in df.columns:\n",
    "        corr = df[feature].corr(df[TARGET])\n",
    "        # Calculate p-value\n",
    "        _, p_value = stats.pearsonr(df[feature].dropna(), \n",
    "                                     df.loc[df[feature].notna(), TARGET])\n",
    "        correlations.append({\n",
    "            'Feature': feature,\n",
    "            'Correlation': corr,\n",
    "            'Abs_Correlation': abs(corr),\n",
    "            'R_Squared': corr**2,\n",
    "            'P_Value': p_value,\n",
    "            'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Abs_Correlation', ascending=False)\n",
    "print(corr_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in corr_df['Correlation']]\n",
    "ax.barh(corr_df['Feature'], corr_df['Correlation'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Correlation with Revenue', fontsize=12)\n",
    "ax.set_title('Numeric Features: Correlation with Box Office Revenue', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/numeric_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre Performance Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENRE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate genre statistics\n",
    "genre_stats = df.groupby('primary_genre').agg({\n",
    "    TARGET: ['count', 'mean', 'median', 'sum'],\n",
    "    'budget': 'mean',\n",
    "    'is_profitable': 'mean',\n",
    "    'roi_pct': 'median'\n",
    "}).round(2)\n",
    "\n",
    "genre_stats.columns = ['Count', 'Mean_Revenue', 'Median_Revenue', 'Total_Revenue', \n",
    "                       'Mean_Budget', 'Profitability_Rate', 'Median_ROI']\n",
    "genre_stats = genre_stats.sort_values('Mean_Revenue', ascending=False)\n",
    "\n",
    "print(genre_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top 10 genres by mean revenue\n",
    "top_10_genres = genre_stats.nlargest(10, 'Mean_Revenue')\n",
    "axes[0, 0].barh(top_10_genres.index, top_10_genres['Mean_Revenue'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[0, 0].set_title('Top 10 Genres by Average Revenue', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].ticklabel_format(style='plain', axis='x')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# Bottom 10 genres\n",
    "bottom_10_genres = genre_stats.nsmallest(10, 'Mean_Revenue')\n",
    "axes[0, 1].barh(bottom_10_genres.index, bottom_10_genres['Mean_Revenue'], color='coral')\n",
    "axes[0, 1].set_xlabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[0, 1].set_title('Bottom 10 Genres by Average Revenue', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].ticklabel_format(style='plain', axis='x')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# Profitability rate\n",
    "top_profitable = genre_stats.nlargest(12, 'Profitability_Rate')\n",
    "axes[1, 0].barh(top_profitable.index, top_profitable['Profitability_Rate'] * 100, color='green', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Profitability Rate (%)', fontsize=12)\n",
    "axes[1, 0].set_title('Top 12 Genres by Profitability Rate', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# ROI\n",
    "top_roi = genre_stats.nlargest(12, 'Median_ROI')\n",
    "axes[1, 1].barh(top_roi.index, top_roi['Median_ROI'], color='purple', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Median ROI (%)', fontsize=12)\n",
    "axes[1, 1].set_title('Top 12 Genres by Median ROI', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/genre_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release Timing Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RELEASE TIMING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Monthly trends\n",
    "monthly_stats = df.groupby('release_month').agg({\n",
    "    TARGET: ['count', 'mean', 'median'],\n",
    "    'budget': 'mean',\n",
    "    'is_profitable': 'mean'\n",
    "}).round(2)\n",
    "monthly_stats.columns = ['Count', 'Mean_Revenue', 'Median_Revenue', 'Mean_Budget', 'Profitability_Rate']\n",
    "print(monthly_stats)\n",
    "\n",
    "# Define seasons\n",
    "summer_months = [5, 6, 7, 8]\n",
    "holiday_months = [11, 12]\n",
    "df['is_summer_temp'] = df['release_month'].isin(summer_months).astype(int)\n",
    "df['is_holiday_temp'] = df['release_month'].isin(holiday_months).astype(int)\n",
    "\n",
    "print(\"\\nSummer (May-Aug) vs Non-Summer:\")\n",
    "print(df.groupby('is_summer_temp')[TARGET].agg(['count', 'mean', 'median']))\n",
    "\n",
    "print(\"\\nHoliday (Nov-Dec) vs Non-Holiday:\")\n",
    "print(df.groupby('is_holiday_temp')[TARGET].agg(['count', 'mean', 'median']))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Monthly revenue\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[0].plot(monthly_stats.index, monthly_stats['Mean_Revenue'], marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "axes[0].fill_between(monthly_stats.index, monthly_stats['Mean_Revenue'], alpha=0.3, color='steelblue')\n",
    "axes[0].set_xlabel('Month', fontsize=12)\n",
    "axes[0].set_ylabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[0].set_title('Average Box Office Revenue by Release Month', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(range(1, 13))\n",
    "axes[0].set_xticklabels(month_names)\n",
    "axes[0].ticklabel_format(style='plain', axis='y')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "# Highlight summer and holiday\n",
    "axes[0].axvspan(4.5, 8.5, alpha=0.2, color='orange', label='Summer (May-Aug)')\n",
    "axes[0].axvspan(10.5, 12.5, alpha=0.2, color='red', label='Holiday (Nov-Dec)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Day of week\n",
    "df['day_of_week_temp'] = df['release_date'].dt.dayofweek\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "day_stats = df.groupby('day_of_week_temp')[TARGET].mean()\n",
    "axes[1].bar(range(7), day_stats, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('Day of Week', fontsize=12)\n",
    "axes[1].set_ylabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[1].set_title('Average Box Office Revenue by Release Day', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(range(7))\n",
    "axes[1].set_xticklabels(day_names)\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/timing_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Clean up temp columns\n",
    "df.drop(['is_summer_temp', 'is_holiday_temp', 'day_of_week_temp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certification Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CERTIFICATION (MPAA RATING) ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cert_stats = df.groupby('us_certification').agg({\n",
    "    TARGET: ['count', 'mean', 'median'],\n",
    "    'budget': 'mean',\n",
    "    'is_profitable': 'mean'\n",
    "}).round(2)\n",
    "cert_stats.columns = ['Count', 'Mean_Revenue', 'Median_Revenue', 'Mean_Budget', 'Profitability_Rate']\n",
    "cert_stats = cert_stats.sort_values('Mean_Revenue', ascending=False)\n",
    "print(cert_stats)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Revenue by certification\n",
    "axes[0].barh(cert_stats.index, cert_stats['Mean_Revenue'], color='teal')\n",
    "axes[0].set_xlabel('Mean Revenue ($)', fontsize=12)\n",
    "axes[0].set_title('Average Revenue by MPAA Rating', fontsize=14, fontweight='bold')\n",
    "axes[0].ticklabel_format(style='plain', axis='x')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Budget by certification\n",
    "axes[1].barh(cert_stats.index, cert_stats['Mean_Budget'], color='orange')\n",
    "axes[1].set_xlabel('Mean Budget ($)', fontsize=12)\n",
    "axes[1].set_title('Average Budget by MPAA Rating', fontsize=14, fontweight='bold')\n",
    "axes[1].ticklabel_format(style='plain', axis='x')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/certification_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language and Other Categorical Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LANGUAGE & OTHER FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# English vs non-English\n",
    "print(\"English vs Non-English Movies:\")\n",
    "language_stats = df.groupby('is_english')[TARGET].agg(['count', 'mean', 'median'])\n",
    "language_stats.index = ['Non-English', 'English']\n",
    "print(language_stats)\n",
    "\n",
    "# Number of genres\n",
    "print(\"\\nNumber of Genres:\")\n",
    "print(df.groupby('num_genres')[TARGET].agg(['count', 'mean', 'median']))\n",
    "\n",
    "# Production companies\n",
    "print(\"\\nNumber of Production Companies:\")\n",
    "print(df.groupby('num_production_companies')[TARGET].agg(['count', 'mean', 'median']).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Business Insights & Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Key Business Questions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY BUSINESS INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Budget-to-revenue ratio\n",
    "median_budget = df['budget'].median()\n",
    "median_revenue = df[TARGET].median()\n",
    "budget_revenue_ratio = median_revenue / median_budget\n",
    "print(f\"\\n1. Budget-to-Revenue Ratio:\")\n",
    "print(f\"   Median Budget: ${median_budget:,.0f}\")\n",
    "print(f\"   Median Revenue: ${median_revenue:,.0f}\")\n",
    "print(f\"   Ratio: {budget_revenue_ratio:.2f}x (for every $1 spent, ${budget_revenue_ratio:.2f} earned)\")\n",
    "\n",
    "# 2. Top genre\n",
    "top_genre = genre_stats.index[0]\n",
    "top_genre_revenue = genre_stats.iloc[0]['Mean_Revenue']\n",
    "print(f\"\\n2. Highest-Grossing Genre:\")\n",
    "print(f\"   {top_genre}: ${top_genre_revenue:,.0f} average revenue\")\n",
    "\n",
    "# 3. Profitability percentage\n",
    "profitability_pct = df['is_profitable'].mean() * 100\n",
    "print(f\"\\n3. Overall Profitability:\")\n",
    "print(f\"   {profitability_pct:.1f}% of movies are profitable (revenue > budget)\")\n",
    "\n",
    "# 4. Release timing impact\n",
    "best_month = monthly_stats['Mean_Revenue'].idxmax()\n",
    "best_month_revenue = monthly_stats.loc[best_month, 'Mean_Revenue']\n",
    "worst_month = monthly_stats['Mean_Revenue'].idxmin()\n",
    "worst_month_revenue = monthly_stats.loc[worst_month, 'Mean_Revenue']\n",
    "timing_difference = (best_month_revenue - worst_month_revenue) / worst_month_revenue * 100\n",
    "print(f\"\\n4. Release Timing Impact:\")\n",
    "print(f\"   Best Month: {month_names[best_month-1]} (${best_month_revenue:,.0f} avg)\")\n",
    "print(f\"   Worst Month: {month_names[worst_month-1]} (${worst_month_revenue:,.0f} avg)\")\n",
    "print(f\"   Difference: {timing_difference:.1f}% higher revenue in best month\")\n",
    "\n",
    "# 5. Optimal runtime\n",
    "optimal_runtime_cat = runtime_revenue['mean'].idxmax()\n",
    "optimal_runtime_revenue = runtime_revenue.loc[optimal_runtime_cat, 'mean']\n",
    "print(f\"\\n5. Optimal Runtime:\")\n",
    "print(f\"   Category: {optimal_runtime_cat}\")\n",
    "print(f\"   Average Revenue: ${optimal_runtime_revenue:,.0f}\")\n",
    "\n",
    "# Save summary\n",
    "business_insights = pd.DataFrame({\n",
    "    'Metric': ['Budget-to-Revenue Ratio', 'Top Genre', 'Profitability %', \n",
    "               'Best Release Month', 'Optimal Runtime'],\n",
    "    'Value': [f\"{budget_revenue_ratio:.2f}x\", \n",
    "              f\"{top_genre} (${top_genre_revenue:,.0f})\",\n",
    "              f\"{profitability_pct:.1f}%\",\n",
    "              f\"{month_names[best_month-1]} (${best_month_revenue:,.0f})\",\n",
    "              f\"{optimal_runtime_cat} (${optimal_runtime_revenue:,.0f})\"]\n",
    "})\n",
    "business_insights.to_csv('../data/processed/bivariate_analysis_summary.csv', index=False)\n",
    "print(\"\\nâœ“ Business insights saved to 'bivariate_analysis_summary.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Correlation Heatmap\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTICOLLINEARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove invalid predictors and identifiers\n",
    "exclude_cols = INVALID_PREDICTORS + ['tmdb_id', 'profit', 'roi_pct', 'is_profitable']\n",
    "numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix: Pre-Release Numeric Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/correlation_heatmap_bivariate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs (|r| > 0.7)\n",
    "print(\"\\nHighly Correlated Pairs (|r| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': corr_matrix.columns[i],\n",
    "                'Feature2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    print(high_corr_df.to_string(index=False))\n",
    "    print(f\"\\nâš  Found {len(high_corr_pairs)} highly correlated pairs - may need regularization\")\n",
    "else:\n",
    "    print(\"âœ“ No highly correlated pairs found - low multicollinearity risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3.2: Tier 1 Feature Engineering\n",
    "### 3.2.1 Temporal Features\n",
    "\n",
    "**Features to Create:**\n",
    "- `release_quarter`: Q1-Q4\n",
    "- `is_summer_release`: 1 if month in [5,6,7,8]\n",
    "- `is_holiday_release`: 1 if month in [11,12]\n",
    "- `release_day_of_week`: 0-6 (Mon-Sun)\n",
    "- `is_weekend_release`: 1 if day in [Fri, Sat, Sun]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "print(\"Creating Temporal Features...\")\n",
    "\n",
    "# Release quarter (Q1-Q4)\n",
    "df['release_quarter'] = df['release_date'].dt.quarter\n",
    "\n",
    "# Summer release (May-Aug)\n",
    "df['is_summer_release'] = df['release_month'].isin([5, 6, 7, 8]).astype(int)\n",
    "\n",
    "# Holiday release (Nov-Dec)\n",
    "df['is_holiday_release'] = df['release_month'].isin([11, 12]).astype(int)\n",
    "\n",
    "# Day of week (0=Monday, 6=Sunday)\n",
    "df['release_day_of_week'] = df['release_date'].dt.dayofweek\n",
    "\n",
    "# Weekend release (Fri=4, Sat=5, Sun=6)\n",
    "df['is_weekend_release'] = df['release_day_of_week'].isin([4, 5, 6]).astype(int)\n",
    "\n",
    "print(\"\\nâœ“ Temporal Features Created:\")\n",
    "print(\"  - release_quarter\")\n",
    "print(\"  - is_summer_release\")\n",
    "print(\"  - is_holiday_release\")\n",
    "print(\"  - release_day_of_week\")\n",
    "print(\"  - is_weekend_release\")\n",
    "\n",
    "# Validation: Check distributions\n",
    "print(\"\\nFeature Distributions:\")\n",
    "print(f\"  Summer releases: {df['is_summer_release'].sum()} ({df['is_summer_release'].mean()*100:.1f}%)\")\n",
    "print(f\"  Holiday releases: {df['is_holiday_release'].sum()} ({df['is_holiday_release'].mean()*100:.1f}%)\")\n",
    "print(f\"  Weekend releases: {df['is_weekend_release'].sum()} ({df['is_weekend_release'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Compare revenue\n",
    "print(\"\\nRevenue Comparison:\")\n",
    "print(f\"  Summer avg: ${df.groupby('is_summer_release')[TARGET].mean()[1]:,.0f}\")\n",
    "print(f\"  Non-summer avg: ${df.groupby('is_summer_release')[TARGET].mean()[0]:,.0f}\")\n",
    "print(f\"  Holiday avg: ${df.groupby('is_holiday_release')[TARGET].mean()[1]:,.0f}\")\n",
    "print(f\"  Non-holiday avg: ${df.groupby('is_holiday_release')[TARGET].mean()[0]:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Cast & Crew Historical Performance\n",
    "\n",
    "**CRITICAL: No Data Leakage**\n",
    "- Historical averages MUST exclude current movie\n",
    "- Use `.shift(1).expanding().mean()` pattern\n",
    "- First-time directors/actors get NaN, then impute with genre-year median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for historical average (NO LEAKAGE)\n",
    "def calculate_historical_avg_revenue(df, group_col, sort_col='release_date', value_col='revenue_worldwide'):\n",
    "    \"\"\"\n",
    "    Calculate historical average revenue EXCLUDING current movie.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        group_col: Column to group by (e.g., 'director_id')\n",
    "        sort_col: Column to sort by (default: 'release_date')\n",
    "        value_col: Column to average (default: 'revenue_worldwide')\n",
    "    \n",
    "    Returns:\n",
    "        Series with historical averages aligned to original index\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values([group_col, sort_col]).copy()\n",
    "    \n",
    "    # Calculate expanding mean shifted by 1 (excludes current)\n",
    "    historical_avg = (\n",
    "        df_sorted.groupby(group_col)[value_col]\n",
    "        .apply(lambda x: x.shift(1).expanding().mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    # Reindex to match original dataframe\n",
    "    return historical_avg.reindex(df.index)\n",
    "\n",
    "print(\"âœ“ Utility function defined: calculate_historical_avg_revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Director Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIRECTOR FEATURES (Historical Performance)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate historical average (excludes current movie)\n",
    "df['director_historical_avg'] = calculate_historical_avg_revenue(df, 'director_id')\n",
    "\n",
    "# First-time director flag\n",
    "df['is_first_time_director'] = df['director_historical_avg'].isna().astype(int)\n",
    "\n",
    "# Director film count (previous films only)\n",
    "df_sorted = df.sort_values(['director_id', 'release_date'])\n",
    "df['director_film_count'] = df_sorted.groupby('director_id').cumcount()\n",
    "\n",
    "print(f\"\\nFirst-time directors: {df['is_first_time_director'].sum()} ({df['is_first_time_director'].mean()*100:.1f}%)\")\n",
    "print(f\"Missing historical averages: {df['director_historical_avg'].isna().sum()}\")\n",
    "\n",
    "# Impute first-time directors with genre-year median\n",
    "print(\"\\nImputing first-time directors with genre-year median...\")\n",
    "genre_year_median = df.groupby(['primary_genre', 'release_year'])[TARGET].transform('median')\n",
    "genre_median = df.groupby('primary_genre')[TARGET].transform('median')\n",
    "overall_median = df[TARGET].median()\n",
    "\n",
    "# Fill strategy: genre-year median -> genre median -> overall median\n",
    "df['director_historical_avg'] = df['director_historical_avg'].fillna(genre_year_median)\n",
    "df['director_historical_avg'] = df['director_historical_avg'].fillna(genre_median)\n",
    "df['director_historical_avg'] = df['director_historical_avg'].fillna(overall_median)\n",
    "\n",
    "print(f\"âœ“ All director features imputed. Missing: {df['director_historical_avg'].isna().sum()}\")\n",
    "\n",
    "# Validation: Check for leakage\n",
    "# For any director's first film, historical_avg should come from imputation\n",
    "print(\"\\nðŸ” Leakage Validation:\")\n",
    "first_films = df[df['director_film_count'] == 0]\n",
    "print(f\"  Directors with 1 film only: {(df.groupby('director_id').size() == 1).sum()}\")\n",
    "print(f\"  First films that were imputed: {first_films['is_first_time_director'].sum()}\")\n",
    "print(\"  âœ“ No leakage detected (first films properly handled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead Actor Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEAD ACTOR FEATURES (Historical Performance)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract lead actor ID (first in pipe-separated list)\n",
    "df['lead_actor_id'] = df['cast_ids'].str.split('|').str[0]\n",
    "\n",
    "# Handle missing lead actors\n",
    "print(f\"Movies with lead actor: {df['lead_actor_id'].notna().sum()} ({df['lead_actor_id'].notna().mean()*100:.1f}%)\")\n",
    "\n",
    "# Calculate historical average for lead actors\n",
    "df['lead_actor_historical_avg'] = calculate_historical_avg_revenue(df, 'lead_actor_id')\n",
    "\n",
    "# First-time lead flag\n",
    "df['is_first_time_lead'] = df['lead_actor_historical_avg'].isna().astype(int)\n",
    "\n",
    "print(f\"\\nFirst-time leads: {df['is_first_time_lead'].sum()} ({df['is_first_time_lead'].mean()*100:.1f}%)\")\n",
    "print(f\"Missing lead actor historical averages: {df['lead_actor_historical_avg'].isna().sum()}\")\n",
    "\n",
    "# Impute with genre-year median\n",
    "print(\"\\nImputing first-time leads with genre-year median...\")\n",
    "df['lead_actor_historical_avg'] = df['lead_actor_historical_avg'].fillna(genre_year_median)\n",
    "df['lead_actor_historical_avg'] = df['lead_actor_historical_avg'].fillna(genre_median)\n",
    "df['lead_actor_historical_avg'] = df['lead_actor_historical_avg'].fillna(overall_median)\n",
    "\n",
    "print(f\"âœ“ All lead actor features imputed. Missing: {df['lead_actor_historical_avg'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-List Actor Count\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"A-LIST ACTOR COUNT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate historical average for ALL actors\n",
    "# First, create actor-movie pairs\n",
    "actor_movie_pairs = []\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row['cast_ids']):\n",
    "        actor_ids = row['cast_ids'].split('|')\n",
    "        for actor_id in actor_ids:\n",
    "            actor_movie_pairs.append({\n",
    "                'actor_id': actor_id,\n",
    "                'tmdb_id': row['tmdb_id'],\n",
    "                'release_date': row['release_date'],\n",
    "                'revenue_worldwide': row[TARGET]\n",
    "            })\n",
    "\n",
    "actor_df = pd.DataFrame(actor_movie_pairs)\n",
    "print(f\"Total actor-movie pairs: {len(actor_df):,}\")\n",
    "\n",
    "# Calculate each actor's historical average\n",
    "actor_df_sorted = actor_df.sort_values(['actor_id', 'release_date'])\n",
    "actor_df_sorted['actor_historical_avg'] = (\n",
    "    actor_df_sorted.groupby('actor_id')['revenue_worldwide']\n",
    "    .apply(lambda x: x.shift(1).expanding().mean())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Define A-list threshold (top 10% of actors by historical average)\n",
    "alist_threshold = actor_df_sorted['actor_historical_avg'].quantile(0.90)\n",
    "print(f\"\\nA-list threshold (top 10%): ${alist_threshold:,.0f}\")\n",
    "\n",
    "# Mark A-list actors\n",
    "actor_df_sorted['is_alist'] = (actor_df_sorted['actor_historical_avg'] >= alist_threshold).astype(int)\n",
    "\n",
    "# Count A-list actors per movie\n",
    "alist_counts = actor_df_sorted[actor_df_sorted['is_alist'] == 1].groupby('tmdb_id').size()\n",
    "df['num_a_list_actors'] = df['tmdb_id'].map(alist_counts).fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\nA-list actor distribution:\")\n",
    "print(df['num_a_list_actors'].value_counts().sort_index().head(10))\n",
    "print(f\"\\nMovies with at least 1 A-lister: {(df['num_a_list_actors'] > 0).sum()} ({(df['num_a_list_actors'] > 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# Validate correlation\n",
    "corr_alist = df['num_a_list_actors'].corr(df[TARGET])\n",
    "print(f\"\\nCorrelation with revenue: r = {corr_alist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Competition Metrics\n",
    "\n",
    "**Features:**\n",
    "- `num_releases_same_weekend`: Count of movies within Â±3 days\n",
    "- `num_releases_same_month`: Count of movies in same month/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition: Same Weekend Releases\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPETITION METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCalculating same-weekend releases (within Â±3 days)...\")\n",
    "print(\"â³ This may take a few minutes for 2,095 movies...\")\n",
    "\n",
    "def count_same_weekend_releases(release_date, all_dates, window_days=3):\n",
    "    \"\"\"Count movies releasing within Â±window_days, excluding current.\"\"\"\n",
    "    lower = release_date - timedelta(days=window_days)\n",
    "    upper = release_date + timedelta(days=window_days)\n",
    "    count = ((all_dates >= lower) & (all_dates <= upper)).sum() - 1  # -1 to exclude current\n",
    "    return max(0, count)\n",
    "\n",
    "# Apply function\n",
    "df['num_releases_same_weekend'] = df['release_date'].apply(\n",
    "    lambda x: count_same_weekend_releases(x, df['release_date'])\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Same-weekend releases calculated\")\n",
    "print(f\"  Distribution:\")\n",
    "print(df['num_releases_same_weekend'].describe())\n",
    "\n",
    "# Validate correlation\n",
    "corr_weekend = df['num_releases_same_weekend'].corr(df[TARGET])\n",
    "print(f\"\\n  Correlation with revenue: r = {corr_weekend:.4f}\")\n",
    "if corr_weekend < 0:\n",
    "    print(\"  âœ“ Negative correlation confirms competition hypothesis\")\n",
    "else:\n",
    "    print(\"  âš  Positive/weak correlation - competition effect unclear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition: Same Month Releases\n",
    "print(\"\\nCalculating same-month releases...\")\n",
    "\n",
    "# Create year-month period\n",
    "df['year_month'] = df['release_date'].dt.to_period('M')\n",
    "\n",
    "# Count per period, then subtract 1 (self)\n",
    "month_counts = df.groupby('year_month').size()\n",
    "df['num_releases_same_month'] = df['year_month'].map(month_counts) - 1\n",
    "\n",
    "print(f\"âœ“ Same-month releases calculated\")\n",
    "print(f\"  Distribution:\")\n",
    "print(df['num_releases_same_month'].describe())\n",
    "\n",
    "# Validate correlation\n",
    "corr_month = df['num_releases_same_month'].corr(df[TARGET])\n",
    "print(f\"\\n  Correlation with revenue: r = {corr_month:.4f}\")\n",
    "\n",
    "# Clean up temporary column\n",
    "df.drop('year_month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Tier 1 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 1 Feature Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIER 1 FEATURES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tier1_features = [\n",
    "    'release_quarter',\n",
    "    'is_summer_release',\n",
    "    'is_holiday_release',\n",
    "    'release_day_of_week',\n",
    "    'is_weekend_release',\n",
    "    'director_historical_avg',\n",
    "    'is_first_time_director',\n",
    "    'director_film_count',\n",
    "    'lead_actor_historical_avg',\n",
    "    'is_first_time_lead',\n",
    "    'num_a_list_actors',\n",
    "    'num_releases_same_weekend',\n",
    "    'num_releases_same_month'\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal Tier 1 Features Created: {len(tier1_features)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, feat in enumerate(tier1_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df[tier1_features].isna().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"  âœ“ No missing values in Tier 1 features\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Calculate correlations with revenue\n",
    "print(\"\\nCorrelations with Revenue:\")\n",
    "tier1_correlations = []\n",
    "for feat in tier1_features:\n",
    "    corr = df[feat].corr(df[TARGET])\n",
    "    tier1_correlations.append({\n",
    "        'Feature': feat,\n",
    "        'Correlation': corr,\n",
    "        'Abs_Correlation': abs(corr)\n",
    "    })\n",
    "\n",
    "tier1_corr_df = pd.DataFrame(tier1_correlations).sort_values('Abs_Correlation', ascending=False)\n",
    "print(tier1_corr_df[['Feature', 'Correlation']].to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in tier1_corr_df['Correlation']]\n",
    "ax.barh(tier1_corr_df['Feature'], tier1_corr_df['Correlation'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Correlation with Revenue', fontsize=12)\n",
    "ax.set_title('Tier 1 Features: Correlation with Box Office Revenue', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/tier1_feature_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Tier 1 feature validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3.3: Tier 2 Features, Final EDA & Dataset Preparation\n",
    "### 3.3.1 Tier 2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 2: Budget & Runtime Categories\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIER 2 FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCreating budget and runtime categories...\")\n",
    "\n",
    "# Budget categories\n",
    "budget_bins = [0, 10e6, 30e6, 75e6, 150e6, float('inf')]\n",
    "budget_labels = ['Micro', 'Low', 'Medium', 'High', 'Blockbuster']\n",
    "df['budget_category'] = pd.cut(df['budget'], bins=budget_bins, labels=budget_labels)\n",
    "\n",
    "print(\"Budget Categories:\")\n",
    "print(df['budget_category'].value_counts().sort_index())\n",
    "\n",
    "# Runtime categories\n",
    "runtime_bins = [0, 90, 110, 130, 300]\n",
    "runtime_labels = ['Short', 'Standard', 'Long', 'Epic']\n",
    "df['runtime_category'] = pd.cut(df['runtime'], bins=runtime_bins, labels=runtime_labels)\n",
    "\n",
    "print(\"\\nRuntime Categories:\")\n",
    "print(df['runtime_category'].value_counts().sort_index())\n",
    "\n",
    "# Multi-genre flag\n",
    "df['is_multi_genre'] = (df['num_genres'] > 1).astype(int)\n",
    "print(f\"\\nMulti-genre movies: {df['is_multi_genre'].sum()} ({df['is_multi_genre'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 2: Sequel Detection\n",
    "print(\"\\nDetecting sequels...\")\n",
    "\n",
    "import re\n",
    "\n",
    "def is_sequel(title):\n",
    "    \"\"\"Detect if movie is a sequel based on title patterns.\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return 0\n",
    "    \n",
    "    patterns = [\n",
    "        r'\\b[IVX]+$',  # Roman numerals at end (e.g., \"Rocky IV\")\n",
    "        r'\\b\\d+$',  # Numbers at end (e.g., \"Toy Story 3\")\n",
    "        r'\\bPart \\d+',  # \"Part 2\"\n",
    "        r'\\bChapter \\d+',  # \"Chapter 2\"\n",
    "        r'\\bVolume \\d+',  # \"Volume 2\"\n",
    "        r'\\b\\d+:\\s',  # \"2: subtitle\"\n",
    "        r'\\d{4}',  # Year in title (often reboots/sequels)\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, title, re.IGNORECASE):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['is_sequel'] = df['title'].apply(is_sequel)\n",
    "\n",
    "print(f\"Sequels detected: {df['is_sequel'].sum()} ({df['is_sequel'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nSequels avg revenue: ${df[df['is_sequel']==1][TARGET].mean():,.0f}\")\n",
    "print(f\"Non-sequels avg revenue: ${df[df['is_sequel']==0][TARGET].mean():,.0f}\")\n",
    "\n",
    "# Use sequel as franchise proxy\n",
    "df['is_franchise'] = df['is_sequel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 2: Director-Genre Match\n",
    "print(\"\\nCalculating director-genre match...\")\n",
    "\n",
    "# Find each director's most common genre (mode)\n",
    "# Only use movies BEFORE current film (no leakage)\n",
    "df_sorted = df.sort_values(['director_id', 'release_date']).copy()\n",
    "\n",
    "def get_director_primary_genre(group):\n",
    "    \"\"\"Get director's most common genre from previous films.\"\"\"\n",
    "    result = []\n",
    "    for idx in range(len(group)):\n",
    "        if idx == 0:\n",
    "            # First film: no history\n",
    "            result.append(None)\n",
    "        else:\n",
    "            # Most common genre from previous films\n",
    "            prev_genres = group.iloc[:idx]['primary_genre']\n",
    "            if len(prev_genres) > 0:\n",
    "                mode_genre = prev_genres.mode()\n",
    "                result.append(mode_genre.iloc[0] if len(mode_genre) > 0 else None)\n",
    "            else:\n",
    "                result.append(None)\n",
    "    return result\n",
    "\n",
    "# Apply function\n",
    "df_sorted['director_primary_genre'] = df_sorted.groupby('director_id', group_keys=False).apply(\n",
    "    lambda x: pd.Series(get_director_primary_genre(x), index=x.index)\n",
    ")\n",
    "\n",
    "# Match current genre with director's primary genre\n",
    "df_sorted['director_genre_match'] = (\n",
    "    df_sorted['primary_genre'] == df_sorted['director_primary_genre']\n",
    ").astype(int)\n",
    "\n",
    "# First films get 0 (no history to match)\n",
    "df_sorted.loc[df_sorted['director_primary_genre'].isna(), 'director_genre_match'] = 0\n",
    "\n",
    "# Merge back to main dataframe\n",
    "df['director_genre_match'] = df_sorted['director_genre_match']\n",
    "\n",
    "print(f\"Movies matching director's primary genre: {df['director_genre_match'].sum()} ({df['director_genre_match'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nMatching avg revenue: ${df[df['director_genre_match']==1][TARGET].mean():,.0f}\")\n",
    "print(f\"Non-matching avg revenue: ${df[df['director_genre_match']==0][TARGET].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 2: Release Month Historical Average\n",
    "print(\"\\nCalculating release month historical average...\")\n",
    "\n",
    "# For each month, calculate historical average (no leakage)\n",
    "df_sorted = df.sort_values('release_date').copy()\n",
    "\n",
    "def calculate_month_historical_avg(group):\n",
    "    \"\"\"Calculate expanding mean for each month.\"\"\"\n",
    "    return group[TARGET].shift(1).expanding().mean()\n",
    "\n",
    "df_sorted['release_month_avg_revenue'] = df_sorted.groupby('release_month', group_keys=False).apply(\n",
    "    lambda x: calculate_month_historical_avg(x)\n",
    ")\n",
    "\n",
    "# Impute first occurrences with overall mean\n",
    "df_sorted['release_month_avg_revenue'] = df_sorted['release_month_avg_revenue'].fillna(df[TARGET].mean())\n",
    "\n",
    "# Merge back\n",
    "df['release_month_avg_revenue'] = df_sorted['release_month_avg_revenue']\n",
    "\n",
    "print(f\"âœ“ Release month historical average calculated\")\n",
    "print(f\"  Missing values: {df['release_month_avg_revenue'].isna().sum()}\")\n",
    "\n",
    "# Correlation\n",
    "corr_month_avg = df['release_month_avg_revenue'].corr(df[TARGET])\n",
    "print(f\"  Correlation with revenue: r = {corr_month_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier 2 Features Summary\n",
    "tier2_features = [\n",
    "    'budget_category',\n",
    "    'runtime_category',\n",
    "    'is_multi_genre',\n",
    "    'is_sequel',\n",
    "    'is_franchise',\n",
    "    'director_genre_match',\n",
    "    'release_month_avg_revenue'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIER 2 FEATURES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal Tier 2 Features Created: {len(tier2_features)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, feat in enumerate(tier2_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_tier2 = df[tier2_features].isna().sum()\n",
    "if missing_tier2.sum() == 0:\n",
    "    print(\"  âœ“ No missing values in Tier 2 features\")\n",
    "else:\n",
    "    print(missing_tier2[missing_tier2 > 0])\n",
    "\n",
    "print(\"\\nâœ“ Tier 2 feature engineering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Feature Selection & Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Correlation Matrix\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FULL FEATURE CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all engineered features\n",
    "all_numeric_features = numeric_features + tier1_features + ['release_month_avg_revenue']\n",
    "\n",
    "# Add target\n",
    "correlation_cols = all_numeric_features + [TARGET]\n",
    "\n",
    "# Calculate correlation\n",
    "full_corr_matrix = df[correlation_cols].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(full_corr_matrix, dtype=bool))\n",
    "sns.heatmap(full_corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, \n",
    "            annot_kws={'size': 7})\n",
    "plt.title('Full Feature Correlation Matrix (All Engineered Features)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/full_feature_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs (|r| > 0.7) excluding target\n",
    "print(\"\\nHighly Correlated Pairs (|r| > 0.7, excluding target):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(full_corr_matrix.columns)-1):  # Exclude target column\n",
    "    for j in range(i+1, len(full_corr_matrix.columns)-1):  # Exclude target column\n",
    "        if abs(full_corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': full_corr_matrix.columns[i],\n",
    "                'Feature2': full_corr_matrix.columns[j],\n",
    "                'Correlation': full_corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    print(high_corr_df.to_string(index=False))\n",
    "    print(f\"\\nâš  Found {len(high_corr_pairs)} highly correlated pairs\")\n",
    "    print(\"  â†’ Consider regularization (Ridge/Lasso) or feature selection\")\n",
    "else:\n",
    "    print(\"âœ“ No highly correlated pairs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor (VIF) Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIANCE INFLATION FACTOR (VIF) ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Prepare data: only numeric features, no missing values\n",
    "vif_data = df[all_numeric_features].copy()\n",
    "vif_data = vif_data.dropna()\n",
    "\n",
    "# Calculate VIF\n",
    "vif_results = []\n",
    "for i, col in enumerate(vif_data.columns):\n",
    "    try:\n",
    "        vif = variance_inflation_factor(vif_data.values, i)\n",
    "        vif_results.append({\n",
    "            'Feature': col,\n",
    "            'VIF': vif\n",
    "        })\n",
    "    except:\n",
    "        vif_results.append({\n",
    "            'Feature': col,\n",
    "            'VIF': np.nan\n",
    "        })\n",
    "\n",
    "vif_df = pd.DataFrame(vif_results).sort_values('VIF', ascending=False)\n",
    "\n",
    "print(\"\\nVIF Interpretation:\")\n",
    "print(\"  VIF < 5: Low multicollinearity\")\n",
    "print(\"  VIF 5-10: Moderate multicollinearity\")\n",
    "print(\"  VIF > 10: High multicollinearity (consider removal/regularization)\")\n",
    "print(\"\\n\" + vif_df.to_string(index=False))\n",
    "\n",
    "# Flag high VIF features\n",
    "high_vif = vif_df[vif_df['VIF'] > 10]\n",
    "if len(high_vif) > 0:\n",
    "    print(f\"\\nâš  {len(high_vif)} features with VIF > 10:\")\n",
    "    print(high_vif.to_string(index=False))\n",
    "    print(\"  â†’ Consider Ridge regression or feature selection\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All features have VIF < 10 (acceptable multicollinearity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Feature Importance Ranking (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM FOREST FEATURE IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data\n",
    "# Include all valid predictors + engineered features\n",
    "feature_cols = (\n",
    "    numeric_features + \n",
    "    tier1_features + \n",
    "    ['release_month_avg_revenue', 'is_multi_genre', 'is_sequel', \n",
    "     'is_franchise', 'director_genre_match']\n",
    ")\n",
    "\n",
    "# Add categorical features (need encoding)\n",
    "categorical_to_encode = ['primary_genre', 'us_certification', 'budget_category', 'runtime_category']\n",
    "\n",
    "# Create working dataframe\n",
    "X = df[feature_cols + categorical_to_encode].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "le_dict = {}\n",
    "for col in categorical_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    X[col + '_encoded'] = le.fit_transform(X[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Drop original categorical columns\n",
    "X = X.drop(categorical_to_encode, axis=1)\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"\\nFeatures for modeling: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "\n",
    "# Train Random Forest (quick model for feature importance)\n",
    "print(\"\\nTraining Random Forest (100 trees, max_depth=10)...\")\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "print(\"âœ“ Model trained\")\n",
    "print(f\"  RÂ² score: {rf.score(X, y):.4f}\")\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Features by Importance:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "top_n = 20\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title(f'Top {top_n} Features by Random Forest Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/feature_importance_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('../data/processed/feature_importance_rf.csv', index=False)\n",
    "print(\"\\nâœ“ Feature importance saved to 'feature_importance_rf.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Final Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Final Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL FEATURE SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define final feature set (based on correlation, VIF, RF importance)\n",
    "final_features = (\n",
    "    # Original numeric\n",
    "    ['budget', 'runtime', 'num_genres', 'num_production_companies'] +\n",
    "    \n",
    "    # Original categorical\n",
    "    ['primary_genre', 'us_certification', 'is_english', 'release_month', 'release_year'] +\n",
    "    \n",
    "    # Tier 1: Temporal\n",
    "    ['release_quarter', 'is_summer_release', 'is_holiday_release', \n",
    "     'release_day_of_week', 'is_weekend_release'] +\n",
    "    \n",
    "    # Tier 1: Cast/Crew\n",
    "    ['director_historical_avg', 'is_first_time_director', 'director_film_count',\n",
    "     'lead_actor_historical_avg', 'is_first_time_lead', 'num_a_list_actors'] +\n",
    "    \n",
    "    # Tier 1: Competition\n",
    "    ['num_releases_same_weekend', 'num_releases_same_month'] +\n",
    "    \n",
    "    # Tier 2\n",
    "    ['budget_category', 'runtime_category', 'is_multi_genre', \n",
    "     'is_sequel', 'director_genre_match', 'release_month_avg_revenue']\n",
    ")\n",
    "\n",
    "# Add identifiers and target\n",
    "keep_cols = (\n",
    "    ['tmdb_id', 'imdb_id', 'title', 'release_date'] +  # Identifiers\n",
    "    final_features +  # Predictors\n",
    "    [TARGET, 'profit', 'roi_pct', 'is_profitable']  # Targets and outcomes\n",
    ")\n",
    "\n",
    "# Create final dataset\n",
    "df_final = df[keep_cols].copy()\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_final.shape[0]} rows Ã— {df_final.shape[1]} columns\")\n",
    "print(f\"Features: {len(final_features)}\")\n",
    "print(f\"  - Original: 9\")\n",
    "print(f\"  - Tier 1: 13\")\n",
    "print(f\"  - Tier 2: 6\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_final = df_final[final_features].isna().sum()\n",
    "if missing_final.sum() == 0:\n",
    "    print(\"  âœ“ No missing values in final features\")\n",
    "else:\n",
    "    print(\"  âš  Missing values detected:\")\n",
    "    print(missing_final[missing_final > 0])\n",
    "    missing_pct = (missing_final.sum() / len(df_final)) * 100\n",
    "    print(f\"  Total missing: {missing_pct:.2f}%\")\n",
    "    if missing_pct < 5:\n",
    "        print(\"  â†’ Acceptable (<5%)\")\n",
    "    else:\n",
    "        print(\"  â†’ May need imputation strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Dataset\n",
    "output_path = '../data/processed/movies_features.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ“ Final dataset saved to: {output_path}\")\n",
    "print(f\"  Shape: {df_final.shape}\")\n",
    "print(f\"  Size: {df_final.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Dictionary\n",
    "feature_dict = pd.DataFrame({\n",
    "    'Feature': final_features,\n",
    "    'Type': [\n",
    "        # Original numeric (4)\n",
    "        'Numeric', 'Numeric', 'Numeric', 'Numeric',\n",
    "        # Original categorical (5)\n",
    "        'Categorical', 'Categorical', 'Binary', 'Numeric', 'Numeric',\n",
    "        # Tier 1: Temporal (5)\n",
    "        'Numeric', 'Binary', 'Binary', 'Numeric', 'Binary',\n",
    "        # Tier 1: Cast/Crew (6)\n",
    "        'Numeric', 'Binary', 'Numeric', 'Numeric', 'Binary', 'Numeric',\n",
    "        # Tier 1: Competition (2)\n",
    "        'Numeric', 'Numeric',\n",
    "        # Tier 2 (6)\n",
    "        'Categorical', 'Categorical', 'Binary', 'Binary', 'Binary', 'Numeric'\n",
    "    ],\n",
    "    'Description': [\n",
    "        # Original\n",
    "        'Movie production budget (USD)',\n",
    "        'Runtime in minutes',\n",
    "        'Number of genres assigned',\n",
    "        'Number of production companies',\n",
    "        'Primary genre classification',\n",
    "        'MPAA rating (G/PG/PG-13/R/etc)',\n",
    "        '1 if original language is English',\n",
    "        'Release month (1-12)',\n",
    "        'Release year',\n",
    "        # Tier 1: Temporal\n",
    "        'Release quarter (1-4)',\n",
    "        '1 if released May-August',\n",
    "        '1 if released November-December',\n",
    "        'Day of week (0=Mon, 6=Sun)',\n",
    "        '1 if released Friday-Sunday',\n",
    "        # Tier 1: Cast/Crew\n",
    "        'Director avg revenue from previous films (no leakage)',\n",
    "        '1 if director has no previous films',\n",
    "        'Number of previous films by director',\n",
    "        'Lead actor avg revenue from previous films (no leakage)',\n",
    "        '1 if lead actor has no previous leading roles',\n",
    "        'Number of A-list actors in cast (top 10% by historical avg)',\n",
    "        # Tier 1: Competition\n",
    "        'Number of movies released within Â±3 days',\n",
    "        'Number of movies released in same month/year',\n",
    "        # Tier 2\n",
    "        'Budget category (Micro/Low/Medium/High/Blockbuster)',\n",
    "        'Runtime category (Short/Standard/Long/Epic)',\n",
    "        '1 if movie has multiple genres',\n",
    "        '1 if movie is a sequel (detected from title)',\n",
    "        '1 if movie genre matches director primary genre (no leakage)',\n",
    "        'Historical average revenue for release month (no leakage)'\n",
    "    ],\n",
    "    'Tier': [\n",
    "        'Original', 'Original', 'Original', 'Original',\n",
    "        'Original', 'Original', 'Original', 'Original', 'Original',\n",
    "        'Tier 1', 'Tier 1', 'Tier 1', 'Tier 1', 'Tier 1',\n",
    "        'Tier 1', 'Tier 1', 'Tier 1', 'Tier 1', 'Tier 1', 'Tier 1',\n",
    "        'Tier 1', 'Tier 1',\n",
    "        'Tier 2', 'Tier 2', 'Tier 2', 'Tier 2', 'Tier 2', 'Tier 2'\n",
    "    ]\n",
    "})\n",
    "\n",
    "feature_dict.to_csv('../data/processed/feature_dictionary.csv', index=False)\n",
    "print(\"\\nâœ“ Feature dictionary saved to 'feature_dictionary.csv'\")\n",
    "print(\"\\n\" + feature_dict.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3 Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 3: FEATURE ENGINEERING - COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET TRANSFORMATION:\")\n",
    "print(f\"  Original dataset: 2,095 movies Ã— 36 columns\")\n",
    "print(f\"  Feature-engineered dataset: {df_final.shape[0]:,} movies Ã— {df_final.shape[1]} columns\")\n",
    "print(f\"  Features created: {len(tier1_features) + len(tier2_features)}\")\n",
    "print(f\"    - Tier 1: {len(tier1_features)}\")\n",
    "print(f\"    - Tier 2: {len(tier2_features)}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BASELINE PERFORMANCE:\")\n",
    "print(f\"  Budget-only model: RÂ² = 0.553\")\n",
    "print(f\"  Budget correlation: r = 0.743\")\n",
    "print(f\"  Target: RÂ² > 0.70 with full feature set\")\n",
    "\n",
    "print(\"\\nðŸ† TOP 5 PREDICTIVE FEATURES (by RF importance):\")\n",
    "for i, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"  {i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… DELIVERABLES:\")\n",
    "print(\"  âœ“ movies_features.csv (final feature-engineered dataset)\")\n",
    "print(\"  âœ“ feature_dictionary.csv (feature descriptions)\")\n",
    "print(\"  âœ“ bivariate_analysis_summary.csv (Step 3.1 findings)\")\n",
    "print(\"  âœ“ feature_importance_rf.csv (RF importance rankings)\")\n",
    "print(\"  âœ“ 8 visualization PNGs saved to visualizations/\")\n",
    "\n",
    "print(\"\\nðŸ”’ DATA LEAKAGE PREVENTION:\")\n",
    "print(\"  âœ“ Historical averages use shift(1).expanding().mean()\")\n",
    "print(\"  âœ“ First-time directors/actors imputed with genre-year median\")\n",
    "print(\"  âœ“ Director-genre match uses only previous films\")\n",
    "print(\"  âœ“ Release month avg uses only past releases\")\n",
    "print(\"  âœ“ No post-release data (vote_count, vote_average, popularity excluded)\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ NEXT STEP: Phase 4 - Preprocessing & Baseline Modeling\")\n",
    "print(\"  â†’ Train/test split (time-based: 2010-2021 train, 2022-2024 test)\")\n",
    "print(\"  â†’ Encode categorical features (one-hot, ordinal)\")\n",
    "print(\"  â†’ Scale numeric features\")\n",
    "print(\"  â†’ Train Linear Regression baseline\")\n",
    "print(\"  â†’ Compare to budget-only baseline (RÂ²=0.553)\")\n",
    "print(\"  â†’ Target: Improve beyond RÂ²=0.70 with full feature set\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ Phase 3 Complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
